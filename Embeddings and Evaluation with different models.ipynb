{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb8b3b6-1dc4-456e-bf37-d3f44f21ebec",
   "metadata": {},
   "source": [
    "Student number: 24206493"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd2aed-60d1-4591-9acb-eaabff5e202b",
   "metadata": {},
   "source": [
    "### Assignment 2: Embeddings\n",
    "\n",
    "#### Task 1: Baseline using CountVectorizer and Logistic Regression Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20f3b1-61f3-4eef-a53a-8a5b55502948",
   "metadata": {},
   "source": [
    "Importing all the required libraries for Task 1, will import others as an when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab66cc6-ef8d-4940-b158-e19f55491a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efafa1da-8c74-42fa-9142-7bf0a3ae56f4",
   "metadata": {},
   "source": [
    "Converting the CSV file into a dataframe and viewing its elements to see what I am going to be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38a915b-63a2-4871-b812-0353d1b6c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BBC_news.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e7a2947-f932-4a32-aa7d-cc8920257397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hariri killing hits Beirut shares  Shares in S...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian banks halt dollar's slide  The dollar re...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Housewives lift Channel 4 ratings  The debut o...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portable PlayStation ready to go  Sony's PlayS...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Georgia plans hidden asset pardon  Georgia is ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German music in a 'zombie' state  The German m...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dent continues Adelaide progress  American Tay...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tory 'stalking horse' Meyer dies  Sir Anthony ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nadal marches on in Mexico  Rafael Nadal conti...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fannie Mae 'should restate books'  US mortgage...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text          Class\n",
       "0  Hariri killing hits Beirut shares  Shares in S...       business\n",
       "1  Asian banks halt dollar's slide  The dollar re...       business\n",
       "2  Housewives lift Channel 4 ratings  The debut o...  entertainment\n",
       "3  Portable PlayStation ready to go  Sony's PlayS...           tech\n",
       "4  Georgia plans hidden asset pardon  Georgia is ...       business\n",
       "5  German music in a 'zombie' state  The German m...  entertainment\n",
       "6  Dent continues Adelaide progress  American Tay...          sport\n",
       "7  Tory 'stalking horse' Meyer dies  Sir Anthony ...       politics\n",
       "8  Nadal marches on in Mexico  Rafael Nadal conti...          sport\n",
       "9  Fannie Mae 'should restate books'  US mortgage...       business"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36763937-a9d9-469e-ad09-c6f6d4537ded",
   "metadata": {},
   "source": [
    "The features are supposed to be extracted from the words, so the words are likely represented in a format that makes it easy to classify them under a label. From the CountVectorization page on scikit-learn, I understood that this function is used to create numerical vectors from words by counting the repetitions of each word. For example, if the sentences are \"This is great\" or \"Is this great?\", this algorithm would represent them as similar vectors. The ordering of the sentences, identifying a word used in different contexts, or determining if words are similar to each other might not be its priority."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c2531-c547-48d2-aef0-0b1cf8494469",
   "metadata": {},
   "source": [
    "Beginning by splitting my data into training and testing sets to prevent any leakages that might lead to inflated accuracy estimates later, I have chosen to keep 25% of the data for testing throughout my experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210b34f8-b0c1-4bba-89da-ed8baae65ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text'].tolist()\n",
    "y = df['Class'].tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4114253b-e3dd-4e78-b6ac-638346cd43f5",
   "metadata": {},
   "source": [
    "I am going to be using a Pipeline + GridSearch approach where I am hardcoding only a couple of things related to the Log Reg classifier, such as:\n",
    "\n",
    "1. max_iter = 100; I tried to let this hyperparameter go through the grid search; however, the process became too lengthy with too many warnings about convergence. 100, which is the default, seemed to be the best bet after trying 200, 300, 500, etc.\n",
    "\n",
    "2. solver = 'liblinear'; the same story as above. I tried to import a warning function to ignore them, but that didn't work either. I am not entirely sure what the issue is here. Also, I read on scikit-learn that 'liblinear' works best for smaller datasets compared to 'lbfgs' and 'saga', so I went ahead with it.\n",
    "\n",
    "3. I also tried to play around with penalties; in all my test cases, l2 seemed to work best, and it's also a default, so I didn't specify it in my final code below.\n",
    "\n",
    "For the CountVectoriser, I wanted to see the effect of a)max features and b)ngram range on its accuracy. Using more features and bigrams along with unigrams should increase the accuracy as the training set will have more text to draw both repetitions and a bit of context(ngrams could with this) as well.\n",
    "\n",
    "Fitting the pipeline and the grid using GridSearchCV on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e23fbd9-34ff-400a-a675-7027719340d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;vectorizer__max_features&#x27;: [None, 1000, 5000, 10000],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (2, 2)]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;vectorizer__max_features&#x27;: [None, 1000, 5000, 10000],\n",
       "                         &#x27;vectorizer__ngram_range&#x27;: [(1, 1), (1, 2), (2, 2)]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 CountVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(max_features=10000, ngram_range=(1, 2))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__max_features': [None, 1000, 5000, 10000],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import warnings \n",
    "# warnings.filterwarnings('ignore')\n",
    "txtpipe = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LogisticRegression(max_iter = 100, solver = 'liblinear'))])\n",
    "\n",
    "#setting up the grid to get the params the work best with our classifier for higher accuracy\n",
    "param_grid = {\n",
    "    'vectorizer__max_features': [None, 1000, 5000, 10000], #this file has >14000 features\n",
    "    'vectorizer__ngram_range': [(1,1), (1,2), (2,2)], \n",
    "\n",
    "    #ngrams seem to be an effort of CountVectorisation to capture the order/context around the words,trying to see if they can help with accuracy\n",
    "\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(txtpipe,param_grid,cv=5,scoring='accuracy',n_jobs=-1,verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39093945-6168-413f-9716-207843dd5d2d",
   "metadata": {},
   "source": [
    "Finding the best parameters after fitting the train data on the basis of accuracy on the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b50408b-8f6b-4fe3-abc4-30b19dccb0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'vectorizer__max_features': 10000, 'vectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f20d51-aef1-4324-b776-1846f96ced8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVscores_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45289cf3-c11a-4981-b672-cf4bf49f9789",
   "metadata": {},
   "source": [
    "Checking the all the results from the grid search and ranking them by their accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32ac34b-35b3-42f0-9584-3e4af15c64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVscores_df = CountVscores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e8d2007-bc29-4a60-9437-afe1e3b4868a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vectorizer__max_features</th>\n",
       "      <th>param_vectorizer__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.635831</td>\n",
       "      <td>0.121264</td>\n",
       "      <td>0.039205</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'vectorizer__max_features': 10000, 'vectorize...</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.913396</td>\n",
       "      <td>0.028031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.581224</td>\n",
       "      <td>0.059588</td>\n",
       "      <td>0.034142</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'vectorizer__max_features': 5000, 'vectorizer...</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.910987</td>\n",
       "      <td>0.031181</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.971065</td>\n",
       "      <td>0.114573</td>\n",
       "      <td>0.043677</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'vectorizer__max_features': None, 'vectorizer...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.908606</td>\n",
       "      <td>0.024945</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.196002</td>\n",
       "      <td>0.021366</td>\n",
       "      <td>0.036366</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>5000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'vectorizer__max_features': 5000, 'vectorizer...</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.906168</td>\n",
       "      <td>0.032835</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229893</td>\n",
       "      <td>0.007837</td>\n",
       "      <td>0.029624</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>10000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'vectorizer__max_features': 10000, 'vectorize...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.903787</td>\n",
       "      <td>0.030617</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.036641</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'vectorizer__max_features': None, 'vectorizer...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.903787</td>\n",
       "      <td>0.030617</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.692723</td>\n",
       "      <td>0.130751</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>None</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'vectorizer__max_features': None, 'vectorizer...</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.889357</td>\n",
       "      <td>0.020988</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.652220</td>\n",
       "      <td>0.098845</td>\n",
       "      <td>0.038183</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'vectorizer__max_features': 1000, 'vectorizer...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.886919</td>\n",
       "      <td>0.033079</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.526380</td>\n",
       "      <td>0.087293</td>\n",
       "      <td>0.027808</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>10000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'vectorizer__max_features': 10000, 'vectorize...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.884567</td>\n",
       "      <td>0.019806</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.447408</td>\n",
       "      <td>0.036259</td>\n",
       "      <td>0.028351</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>5000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'vectorizer__max_features': 5000, 'vectorizer...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.882186</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.189529</td>\n",
       "      <td>0.031922</td>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'vectorizer__max_features': 1000, 'vectorizer...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.877338</td>\n",
       "      <td>0.028115</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.446750</td>\n",
       "      <td>0.076484</td>\n",
       "      <td>0.033763</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>1000</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>{'vectorizer__max_features': 1000, 'vectorizer...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.841308</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.635831      0.121264         0.039205        0.002265   \n",
       "1        0.581224      0.059588         0.034142        0.001128   \n",
       "2        0.971065      0.114573         0.043677        0.005381   \n",
       "3        0.196002      0.021366         0.036366        0.000915   \n",
       "4        0.229893      0.007837         0.029624        0.007728   \n",
       "5        0.240573      0.004186         0.036641        0.002063   \n",
       "6        0.692723      0.130751         0.030425        0.002349   \n",
       "7        0.652220      0.098845         0.038183        0.010099   \n",
       "8        0.526380      0.087293         0.027808        0.004244   \n",
       "9        0.447408      0.036259         0.028351        0.006055   \n",
       "10       0.189529      0.031922         0.034234        0.007569   \n",
       "11       0.446750      0.076484         0.033763        0.008254   \n",
       "\n",
       "   param_vectorizer__max_features param_vectorizer__ngram_range  \\\n",
       "0                           10000                        (1, 2)   \n",
       "1                            5000                        (1, 2)   \n",
       "2                            None                        (1, 2)   \n",
       "3                            5000                        (1, 1)   \n",
       "4                           10000                        (1, 1)   \n",
       "5                            None                        (1, 1)   \n",
       "6                            None                        (2, 2)   \n",
       "7                            1000                        (1, 2)   \n",
       "8                           10000                        (2, 2)   \n",
       "9                            5000                        (2, 2)   \n",
       "10                           1000                        (1, 1)   \n",
       "11                           1000                        (2, 2)   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'vectorizer__max_features': 10000, 'vectorize...           0.940476   \n",
       "1   {'vectorizer__max_features': 5000, 'vectorizer...           0.940476   \n",
       "2   {'vectorizer__max_features': None, 'vectorizer...           0.928571   \n",
       "3   {'vectorizer__max_features': 5000, 'vectorizer...           0.940476   \n",
       "4   {'vectorizer__max_features': 10000, 'vectorize...           0.928571   \n",
       "5   {'vectorizer__max_features': None, 'vectorizer...           0.928571   \n",
       "6   {'vectorizer__max_features': None, 'vectorizer...           0.916667   \n",
       "7   {'vectorizer__max_features': 1000, 'vectorizer...           0.928571   \n",
       "8   {'vectorizer__max_features': 10000, 'vectorize...           0.904762   \n",
       "9   {'vectorizer__max_features': 5000, 'vectorizer...           0.892857   \n",
       "10  {'vectorizer__max_features': 1000, 'vectorizer...           0.904762   \n",
       "11  {'vectorizer__max_features': 1000, 'vectorizer...           0.857143   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.879518           0.939759           0.927711   \n",
       "1            0.879518           0.939759           0.927711   \n",
       "2            0.879518           0.939759           0.915663   \n",
       "3            0.867470           0.939759           0.915663   \n",
       "4            0.867470           0.939759           0.915663   \n",
       "5            0.867470           0.939759           0.915663   \n",
       "6            0.879518           0.855422           0.891566   \n",
       "7            0.843373           0.915663           0.891566   \n",
       "8            0.867470           0.855422           0.903614   \n",
       "9            0.867470           0.843373           0.903614   \n",
       "10           0.843373           0.903614           0.891566   \n",
       "11           0.783133           0.843373           0.903614   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.879518         0.913396        0.028031                1  \n",
       "1            0.867470         0.910987        0.031181                2  \n",
       "2            0.879518         0.908606        0.024945                3  \n",
       "3            0.867470         0.906168        0.032835                4  \n",
       "4            0.867470         0.903787        0.030617                5  \n",
       "5            0.867470         0.903787        0.030617                5  \n",
       "6            0.903614         0.889357        0.020988                7  \n",
       "7            0.855422         0.886919        0.033079                8  \n",
       "8            0.891566         0.884567        0.019806                9  \n",
       "9            0.903614         0.882186        0.023474               10  \n",
       "10           0.843373         0.877338        0.028115               11  \n",
       "11           0.819277         0.841308        0.040017               12  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVscores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5f5f9-3a76-440e-be46-a95087d2c7c4",
   "metadata": {},
   "source": [
    "Across our 5‑fold CV grid search over vocabulary size (max_features), and n‑gram range, the best configuration for the hyperparameters has been:\n",
    "- max_features = 10000, ngram_range = (1, 2)\n",
    "\n",
    "ngram range of (1,2) is a consistent parameter in the top five configrations. This setting achieved a mean CV accuracy of 0.9134 (std ≈ 0.0280), placing it 1st out of 12 candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "604642eb-c945-4fdc-80ec-aee5c90bcf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935251798561151\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.93      0.93      0.93        30\n",
      "entertainment       0.91      0.88      0.89        24\n",
      "     politics       0.96      0.96      0.96        26\n",
      "        sport       0.94      1.00      0.97        33\n",
      "         tech       0.92      0.88      0.90        26\n",
      "\n",
      "     accuracy                           0.94       139\n",
      "    macro avg       0.93      0.93      0.93       139\n",
      " weighted avg       0.93      0.94      0.93       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix ,display_labels=grid_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e2ba6b-a667-4515-b11c-5c5ab868c1ca",
   "metadata": {},
   "source": [
    "#### Main Findings:\n",
    "\n",
    "1. ~94% accuracy on the predictions using CountVectorizer.\n",
    "\n",
    "2. Vocabulary size: Allowing up to 10000 features outperformed no limit and 5000.\n",
    "\n",
    "3. N‑grams: Including bigrams (ngram_range=(1,2)) consistently yielded top performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7988ffe-46d6-414d-9a4f-c0fab103f4f4",
   "metadata": {},
   "source": [
    "#### Task 2: Doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2437e87d-1317-4000-b59c-9f08d5d45118",
   "metadata": {},
   "source": [
    "Repeating the same process for Doc2Vec. ChatGPT suggested to create a class if I had to conduct a GS. It seamlessly got intergrated with the pipleine and GS feature selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d39a7e62-8dfd-4d24-a572-8d31a1edda2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c204a89-d5de-4802-a243-b8cbc9185a3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=50, window=5, min_count=2, epochs=20, seed=42, workers=4, dm = 1):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.epochs = epochs\n",
    "        self.seed = seed\n",
    "        self.workers = workers\n",
    "        self.dm = dm\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        tagged = [\n",
    "            TaggedDocument(words=doc.split(), tags=[i])\n",
    "            for i, doc in enumerate(X)\n",
    "        ]\n",
    "        self.model_ = Doc2Vec(\n",
    "            vector_size=self.vector_size,\n",
    "            window=self.window,\n",
    "            min_count=self.min_count,\n",
    "            workers=self.workers,\n",
    "            epochs=self.epochs,\n",
    "            seed=self.seed, \n",
    "            dm = self.dm\n",
    "        )\n",
    "        self.model_.build_vocab(tagged)\n",
    "        self.model_.train(tagged,\n",
    "                          total_examples=len(tagged),\n",
    "                          epochs=self.epochs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            self.model_.infer_vector(doc.split())\n",
    "            for doc in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de33551d-2410-4236-b71f-77013bfb1e66",
   "metadata": {},
   "source": [
    "For the param grid for Doc2Vec, I tried to check with hyper-parameters such as:\n",
    "1. dm that defines the training algorithm. If dm=1, ‘distributed memory’ (PV-DM) is used. Otherwise, distributed bag of words (PV-DBOW) is employed. This helps with preserving the order/context of the words in which they appear by creating a paragraph vectors  \n",
    "2. Vector size which takes care of the dimensionality of the feature vectors\n",
    "3. window is how many words can be used to tune the maximum distance between the current and predicted word within a sentence\n",
    "4. min_count that ignores all words with total frequency lower than the integer its initialised with\n",
    "5. Epochs that figures the number of iterations (epochs) over the corpus. Defaults to 10 for Doc2Vec.\n",
    "\n",
    "I will be running a 3 fold CV for Doc2Vec as its computationally heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf87c2c-3267-48fa-9809-f507abf55277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 512 candidates, totalling 1536 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;d2v&#x27;, Doc2VecTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;d2v__dm&#x27;: [0, 1], &#x27;d2v__epochs&#x27;: [20, 40, 60, 80],\n",
       "                         &#x27;d2v__min_count&#x27;: [1, 2, 3, 4],\n",
       "                         &#x27;d2v__vector_size&#x27;: [16, 32, 64, 128],\n",
       "                         &#x27;d2v__window&#x27;: [2, 3, 5, 7]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;d2v&#x27;, Doc2VecTransformer()),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(solver=&#x27;liblinear&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;d2v__dm&#x27;: [0, 1], &#x27;d2v__epochs&#x27;: [20, 40, 60, 80],\n",
       "                         &#x27;d2v__min_count&#x27;: [1, 2, 3, 4],\n",
       "                         &#x27;d2v__vector_size&#x27;: [16, 32, 64, 128],\n",
       "                         &#x27;d2v__window&#x27;: [2, 3, 5, 7]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;d2v&#x27;,\n",
       "                 Doc2VecTransformer(dm=0, epochs=60, min_count=1,\n",
       "                                    vector_size=128, window=2)),\n",
       "                (&#x27;clf&#x27;, LogisticRegression(solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Doc2VecTransformer</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Doc2VecTransformer(dm=0, epochs=60, min_count=1, vector_size=128, window=2)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('d2v', Doc2VecTransformer()),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'d2v__dm': [0, 1], 'd2v__epochs': [20, 40, 60, 80],\n",
       "                         'd2v__min_count': [1, 2, 3, 4],\n",
       "                         'd2v__vector_size': [16, 32, 64, 128],\n",
       "                         'd2v__window': [2, 3, 5, 7]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('d2v', Doc2VecTransformer()),\n",
    "    ('clf', LogisticRegression(max_iter=100, solver = 'liblinear'))\n",
    "])\n",
    "param_grid = {\n",
    "    'd2v__dm': [0, 1],\n",
    "    'd2v__vector_size': [16, 32, 64, 128],\n",
    "    'd2v__window': [2, 3, 5, 7],\n",
    "    'd2v__min_count': [1, 2, 3, 4],\n",
    "    'd2v__epochs': [20, 40, 60, 80],\n",
    "\n",
    "}\n",
    "\n",
    "grid = GridSearchCV( estimator=pipe, param_grid=param_grid,cv=3,scoring='accuracy',n_jobs=-1,verbose=2)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c7edd50-efb5-4edf-b7e2-e6aea9643bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_count': 1, 'd2v__vector_size': 128, 'd2v__window': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found:\")\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86da6e15-660f-43cd-bdc6-40cbd90e766e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_d2v__dm</th>\n",
       "      <th>param_d2v__epochs</th>\n",
       "      <th>param_d2v__min_count</th>\n",
       "      <th>param_d2v__vector_size</th>\n",
       "      <th>param_d2v__window</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.378001</td>\n",
       "      <td>3.214738</td>\n",
       "      <td>5.828730</td>\n",
       "      <td>0.705659</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>{'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_co...</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.959146</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.332565</td>\n",
       "      <td>1.402620</td>\n",
       "      <td>5.600957</td>\n",
       "      <td>0.682336</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>{'d2v__dm': 0, 'd2v__epochs': 80, 'd2v__min_co...</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.935252</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.956765</td>\n",
       "      <td>0.015477</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.530761</td>\n",
       "      <td>2.222982</td>\n",
       "      <td>5.323239</td>\n",
       "      <td>0.527800</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>{'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_co...</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.942446</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.956748</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.610583</td>\n",
       "      <td>1.266181</td>\n",
       "      <td>4.227626</td>\n",
       "      <td>0.415585</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>{'d2v__dm': 0, 'd2v__epochs': 40, 'd2v__min_co...</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.956748</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.099592</td>\n",
       "      <td>1.906534</td>\n",
       "      <td>3.994493</td>\n",
       "      <td>0.829115</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>{'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_co...</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.956748</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.067622</td>\n",
       "      <td>2.008668</td>\n",
       "      <td>4.167562</td>\n",
       "      <td>0.257446</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>{'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_co...</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.956748</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.378324</td>\n",
       "      <td>0.147223</td>\n",
       "      <td>2.880401</td>\n",
       "      <td>0.260604</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>{'d2v__dm': 0, 'd2v__epochs': 40, 'd2v__min_co...</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.956748</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.614810</td>\n",
       "      <td>0.252249</td>\n",
       "      <td>3.721893</td>\n",
       "      <td>0.047511</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>{'d2v__dm': 0, 'd2v__epochs': 40, 'd2v__min_co...</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956730</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.987148</td>\n",
       "      <td>0.582150</td>\n",
       "      <td>5.478474</td>\n",
       "      <td>0.346532</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>{'d2v__dm': 0, 'd2v__epochs': 80, 'd2v__min_co...</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.942446</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956730</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.432954</td>\n",
       "      <td>1.504437</td>\n",
       "      <td>4.009582</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>{'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_co...</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.942446</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956730</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      26.378001      3.214738         5.828730        0.705659   \n",
       "1      26.332565      1.402620         5.600957        0.682336   \n",
       "2      25.530761      2.222982         5.323239        0.527800   \n",
       "3      18.610583      1.266181         4.227626        0.415585   \n",
       "4      17.099592      1.906534         3.994493        0.829115   \n",
       "5      20.067622      2.008668         4.167562        0.257446   \n",
       "6      14.378324      0.147223         2.880401        0.260604   \n",
       "7      14.614810      0.252249         3.721893        0.047511   \n",
       "8      21.987148      0.582150         5.478474        0.346532   \n",
       "9      17.432954      1.504437         4.009582        0.228254   \n",
       "\n",
       "   param_d2v__dm  param_d2v__epochs  param_d2v__min_count  \\\n",
       "0              0                 60                     1   \n",
       "1              0                 80                     2   \n",
       "2              0                 60                     1   \n",
       "3              0                 40                     1   \n",
       "4              0                 60                     4   \n",
       "5              0                 60                     2   \n",
       "6              0                 40                     2   \n",
       "7              0                 40                     2   \n",
       "8              0                 80                     4   \n",
       "9              0                 60                     3   \n",
       "\n",
       "   param_d2v__vector_size  param_d2v__window  \\\n",
       "0                     128                  2   \n",
       "1                     128                  5   \n",
       "2                     128                  5   \n",
       "3                     128                  5   \n",
       "4                     128                  2   \n",
       "5                     128                  2   \n",
       "6                     128                  2   \n",
       "7                     128                  5   \n",
       "8                     128                  2   \n",
       "9                     128                  2   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_co...           0.964029   \n",
       "1  {'d2v__dm': 0, 'd2v__epochs': 80, 'd2v__min_co...           0.964029   \n",
       "2  {'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_co...           0.964029   \n",
       "3  {'d2v__dm': 0, 'd2v__epochs': 40, 'd2v__min_co...           0.949640   \n",
       "4  {'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_co...           0.956835   \n",
       "5  {'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_co...           0.956835   \n",
       "6  {'d2v__dm': 0, 'd2v__epochs': 40, 'd2v__min_co...           0.949640   \n",
       "7  {'d2v__dm': 0, 'd2v__epochs': 40, 'd2v__min_co...           0.964029   \n",
       "8  {'d2v__dm': 0, 'd2v__epochs': 80, 'd2v__min_co...           0.971223   \n",
       "9  {'d2v__dm': 0, 'd2v__epochs': 60, 'd2v__min_co...           0.971223   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.949640           0.963768         0.959146        0.006722   \n",
       "1           0.935252           0.971014         0.956765        0.015477   \n",
       "2           0.942446           0.963768         0.956748        0.010113   \n",
       "3           0.956835           0.963768         0.956748        0.005768   \n",
       "4           0.949640           0.963768         0.956748        0.005768   \n",
       "5           0.949640           0.963768         0.956748        0.005768   \n",
       "6           0.956835           0.963768         0.956748        0.005768   \n",
       "7           0.949640           0.956522         0.956730        0.005876   \n",
       "8           0.942446           0.956522         0.956730        0.011749   \n",
       "9           0.942446           0.956522         0.956730        0.011749   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                2  \n",
       "2                3  \n",
       "3                3  \n",
       "4                3  \n",
       "5                3  \n",
       "6                3  \n",
       "7                8  \n",
       "8                8  \n",
       "9                8  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2Vscores_df = pd.DataFrame(grid.cv_results_)\n",
    "D2Vscores_df = D2Vscores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "D2Vscores_df.head(10)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bd9a1-e67d-4b4f-81ac-1efc24d010fb",
   "metadata": {},
   "source": [
    "Across our 3‑fold CV grid search overdm, vector size, window, min_count, and epochs, the best configuration for the hyperparameters has been:\n",
    "DM = 0, Vector size = 128, window = 2, min_count = 1, epochs = 60\n",
    "\n",
    "Top models used dm = 0, meaning PV-DBOW worked better than PV-DM and vector size of 128 is a consistent parameter in the top four configrations. This setting achieved a mean test accuracy of 0.959 (std ≈ 0.0006), placing it 1st out of 512 candidates. The CV process ended up being extremely computationally heavy for me in the hindsight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fe651ca-2381-4c03-97e3-1f8ce8cf1782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec + Logistic Regression Accuracy: 0.9568345323741008\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.97      0.97      0.97        30\n",
      "entertainment       0.96      0.96      0.96        24\n",
      "     politics       0.93      0.96      0.94        26\n",
      "        sport       1.00      1.00      1.00        33\n",
      "         tech       0.92      0.88      0.90        26\n",
      "\n",
      "     accuracy                           0.96       139\n",
      "    macro avg       0.95      0.95      0.95       139\n",
      " weighted avg       0.96      0.96      0.96       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGwCAYAAAC0HlECAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAX2FJREFUeJzt3XlcVFX/B/DPZR22YZdFEVERV1xLyV1RsDS3Hs3sEczUStI01MxUyMyyxz2zsgLt51a5ZOaahbvkhpYLAkJq4i4iO8yc3x/k5IjCDHNhBvi8X6/7krn3nnu/c7ww3znn3HMlIYQAEREREZXKzNgBEBEREVUFTJqIiIiIdMCkiYiIiEgHTJqIiIiIdMCkiYiIiEgHTJqIiIiIdMCkiYiIiEgHFsYOgKoGtVqNq1evwsHBAZIkGTscIiLSkxAC9+/fh7e3N8zMKq7NJC8vDwUFBQYfx8rKCgqFQoaI5MOkiXRy9epV+Pj4GDsMIiIy0OXLl1GnTp0KOXZeXh78fO1x7YbK4GN5enoiNTXVpBInJk2kEwcHBwDAl/ubwsbe3MjRmLavW9c3dghVgpmtjbFDqBLUObnGDoGqiSIU4gC2af6eV4SCggJcu6HCX8frQelQ/taszPtq+LZNQ0FBAZMmqnoedMnZ2JvD1oFJU2ksJEtjh1AlmElWxg6hSlBLRcYOgaqLfx6aVhlDLOwdJNg7lP88apjmMBAmTURERCQrlVBDZcCTbVVCLV8wMmLSRERERLJSQ0CN8mdNhpStSJxygIiIiEgHbGkiIiIiWamhhiEdbIaVrjhMmoiIiEhWKiGgEuXvYjOkbEVi9xwRERGRDtjSRERERLKqrgPBmTQRERGRrNQQUFXDpIndc0REREQ6YEsTERERyYrdc0REREQ64N1zRERERDUYW5qIiIhIVup/FkPKmyImTURERCQrlYF3zxlStiIxaSIiIiJZqUTxYkh5U8QxTUREREQ6YEsTERERyYpjmoiIiIh0oIYEFSSDypsids8RERER6YAtTURERCQrtSheDClvipg0ERERkaxUBnbPGVK2IrF7joiIiEgHbGkiIiIiWVXXliYmTURERCQrtZCgFgbcPWdA2YrE7jkiIiIiHbCliYiIiGTF7jkiIiIiHahgBpUBnVkqGWORE7vniIiISFbinzFN5V2EnmOali9fjsDAQCiVSiiVSgQFBWH79u2a7Xl5eRg3bhxcXV1hb2+PwYMH4/r163q/LyZNREREVKXVqVMHH330EY4fP45jx46hR48e6N+/P86cOQMAmDhxIn766Sd8//332Lt3L65evYpBgwbpfR52z5WiW7duaNWqFRYtWlQhx5ckCZs2bcKAAQMq5PjVwYnPnXFxlx0yLlrB3FoNzzZ56DD5NpzrF2r2ufeXBQ5/7Ib0YzZQFUio2yUbnWbegq2bqTbwVq5+4bfwwus34OJehItnbfDZe7WRmGBr7LBMRvOnMvHC6Kto2CwLrh6FeP+1ABz+xcXYYZkkXku6YT1V/pimfv36ab2eM2cOli9fjiNHjqBOnTr4+uuvsWbNGvTo0QMAEBMTgyZNmuDIkSPo0KGDzudhS5MRpaeno0+fPsYOw6Rd/V2B5sPvYdD3V9Av9irUhRK2jvRGYU7xL1RhjoStI2sDAJ7/9m8MXH8FqkIJ28d6QZjqY7IrUdfn72LMrKtYvcAT40Ia4eJZBeasuQhH18KyC9cQChsVLp6zxWdRfsYOxaTxWtIN66mYSpgZvABAZmam1pKfn1/2uVUqrFu3DtnZ2QgKCsLx48dRWFiI4OBgzT6NGzdG3bp1cfjwYb3eF5MmI/L09IS1tbWxwzBpfb9JR+PB9+HiXwC3JgXo8fF1ZF21xM0/i+vt2nEF7v9tgR4fX4drQAFcAwrQY94N3PjDGn8ftjFy9MY3aMwt7Fjjgl3rXXApSYElU+sgP1dCyLA7xg7NZBzb54xVC+vi0G5XY4di0ngt6Yb1JC8fHx84Ojpqlrlz5z5x3z/++AP29vawtrbGa6+9hk2bNqFp06a4du0arKys4OTkpLW/h4cHrl27plc8TJrKUFRUhIiICDg6OsLNzQ0zZsyAEMVPEpQkCZs3b9ba38nJCbGxsQCAgoICREREwMvLCwqFAr6+vlr/4Q+XT0tLgyRJ2LhxI7p37w5bW1u0bNmyRBZ84MABdO7cGTY2NvDx8cH48eORnZ2t2f7ZZ5/B398fCoUCHh4eeOGFFzTbfvjhB7Ro0QI2NjZwdXVFcHCwVtmqoCDLHABg7VTcjKQqkAAJMLf69+mOFlZqSGZA+vGanTRZWKrhH5iDE/sdNOuEkHByvwOats0xYmRU1fBa0g3r6V9qSFDDzICluDfh8uXLuHfvnmaZNm3aE88ZEBCAhIQExMfH4/XXX0dYWBjOnj0r6/ti0lSGlStXwsLCAr///jsWL16MBQsW4KuvvtKp7JIlS7BlyxZ89913SExMxOrVq1GvXr1Sy0yfPh2RkZFISEhAo0aNMGzYMBQVFQEAUlJSEBoaisGDB+P06dNYv349Dhw4gIiICADAsWPHMH78eLz//vtITEzEjh070KVLFwDFXYHDhg3DK6+8gnPnziEuLg6DBg3SJICPys/PL9EsamxCDRz8wA2ebXPh2qgAAODRKg+WNmoc/sQNhbkSCnMkHPrYDUIlIeeGuZEjNi6liwrmFkDGTe2hi3dvWcDZvchIUVFVxGtJN6ynfz0Y02TIAkBzN9yDpbTeGSsrKzRs2BBt27bF3Llz0bJlSyxevBienp4oKChARkaG1v7Xr1+Hp6enXu+LA8HL4OPjg4ULF0KSJAQEBOCPP/7AwoULMXr06DLLXrp0Cf7+/ujUqRMkSYKvr2+ZZSIjI/Hcc88BAKKjo9GsWTMkJyejcePGmDt3LoYPH4633noLAODv748lS5aga9euWL58OS5dugQ7Ozv07dsXDg4O8PX1RevWrQEUJ01FRUUYNGiQJo4WLVo8MY65c+ciOjq6zHgr074od9xJssKAtVc062xc1ei95Br2zaqFP1Y5QjID/Pveh1uzPH4lICKqwdRqNfLz89G2bVtYWlpiz549GDx4MAAgMTERly5dQlBQkF7HZNJUhg4dOkCS/h3FHxQUhPnz50OlKvvOrPDwcPTq1QsBAQEIDQ1F37590bt371LLBAYGan728vICANy4cQONGzfGqVOncPr0aaxevVqzjxACarUaqamp6NWrF3x9fVG/fn2EhoYiNDQUAwcO1HT19ezZEy1atEBISAh69+6NF154Ac7Ozo+NY9q0aZg0aZLmdWZmJnx8fMp8zxVlf7Qb/vrNFgPW/A17L+269+mci+G//oXcO2YwswCslWrEBtWD0ifLSNGahsw75lAVAU6PfMN1divC3Zv81Sfd8VrSDevpXw8P5i5f+cf3gjzJtGnT0KdPH9StWxf379/HmjVrEBcXh507d8LR0RGjRo3CpEmT4OLiAqVSiTfffBNBQUF63TkH8Lu4QSRJKtG9VVj47x0Sbdq0QWpqKmbPno3c3FwMGTJEa4zR41haWmodHyjOlgEgKysLY8eORUJCgmY5deoUkpKS0KBBAzg4OODEiRNYu3YtvLy8MHPmTLRs2RIZGRkwNzfH7t27sX37djRt2hRLly5FQEAAUlNTHxuHtbV1iWZRYxCiOGFK3W2P57+9CqXPk5u4bVzUsFaqceWwDXJvm6Nez6o1XktuRYVmSDpti9ad7mvWSZJAq05ZOHu8Zt3+TIbhtaQb1tO/isc0Gbbo48aNGxgxYgQCAgLQs2dPHD16FDt37kSvXr0AAAsXLkTfvn0xePBgdOnSBZ6enti4caPe76tmpb7lEB8fr/X6yJEj8Pf3h7m5Odzd3ZGenq7ZlpSUhJwc7cF+SqUSQ4cOxdChQ/HCCy8gNDQUd+7cgYuL/vPAtGnTBmfPnkXDhg2fuI+FhQWCg4MRHByMWbNmwcnJCb/++isGDRoESZLQsWNHdOzYETNnzoSvry82bdqk1aJkavZHuSPpJ3v0WZ4OKzs1cm4Wj1OyclDDQlGcsJ7/wQFODQpg46LC9QQFDnzgjpYjM7TmcqqpNn7phshFl3HhlC0ST9pi4OibUNiqsWsd5yF6QGGrgrdvnua1h08e6jfJxv0MC9xM592tD/Ba0g3ryTi+/vrrUrcrFAosW7YMy5YtM+g8TJrKcOnSJUyaNAljx47FiRMnsHTpUsyfPx8A0KNHD3z66acICgqCSqXC1KlTtVqKFixYAC8vL7Ru3RpmZmb4/vvv4enpWeK2R11NnToVHTp0QEREBF599VXY2dnh7Nmz2L17Nz799FNs3boVFy9eRJcuXeDs7Ixt27ZBrVYjICAA8fHx2LNnD3r37o1atWohPj4eN2/eRJMmTeSopgpzZo0jAODHl+tore/+0XU0Hlz8bS4j1QpH5rsi/545HGoXou3rdxE4MqOyQzVJe7c4w9FVhRGTr8HZvQgXz9hg+nA/ZNyyLLtwDeHfIgvzVv97h83Y6X8BAHZvcMeCqU/+glLT8FrSDeupmNrAZ8+poV/3XGVh0lSGESNGIDc3F08//TTMzc0xYcIEjBkzBgAwf/58jBw5Ep07d4a3tzcWL16M48ePa8o6ODhg3rx5SEpKgrm5OZ566ils27YNZmblu5ACAwOxd+9eTJ8+HZ07d4YQAg0aNMDQoUMBFE93sHHjRkRFRSEvLw/+/v5Yu3YtmjVrhnPnzmHfvn1YtGgRMjMz4evri/nz55v85JqvJyWXuU+HybfRYfLtSoimatoS44YtMW7GDsNk/RHviD4N9RsMWlPxWtIN66nyxzRVFkk86Z5zoodkZmbC0dER355sAVuHmn0rf1mW+7N1QhdmtjVrjEd5qXNq1vw+VHGKRCHi8CPu3btXYeNUH3xWrElobtBnRc59FV5q9WeFxloeHAhOREREpAN2zxEREZGsVEKCShjwwF4DylYkJk1EREQkK5WBA8FVJjoQnN1zRERERDpgSxMRERHJSi3MoDbg7jm1id6jxqSJiIiIZMXuOSIiIqIajC1NREREJCs1DLsDTi1fKLJi0kRERESyUsMMaoMeo2KaHWGmGRURERGRiWFLExEREcnK8GfPmWabDpMmIiIikpUaEtQwZEwTZwQnIiKiGqC6tjSZZlREREREJoYtTURERCQrwye3NM02HSZNREREJCu1kKA2ZJ4mA8pWJNNM5YiIiIhMDFuaiIiISFZqA7vnTHVySyZNREREJCu1MIPagDvgDClbkUwzKiIiIiITw5YmIiIikpUKElQGTFBpSNmKxKSJiIiIZMXuOSIiIqIajC1NREREJCsVDOtiU8kXiqyYNBEREZGsqmv3HJMmIiIikhUf2EtERERUg7GliYiIiGQlIEFtwJgmwSkHiIiIqCZg9xwRERFRDcaWJtLL163rw0KyNHYYJk29x8fYIVQNPS8bOwKqRsxsbY0dgskzEwVATuWcSy0kqEX5u9gMKVuRmDQRERGRrFQwg8qAzixDylYk04yKiIiIyMSwpYmIiIhkxe45IiIiIh2oYQa1AZ1ZhpStSKYZFREREZGJYUsTERERyUolJKgM6GIzpGxFYtJEREREsuKYJiIiIiIdCGEGtQGzegvOCE5ERERUdbGliYiIiGSlggSVAQ/dNaRsRWLSRERERLJSC8PGJamFjMHIiN1zREREVKXNnTsXTz31FBwcHFCrVi0MGDAAiYmJWvt069YNkiRpLa+99ppe52HSRERERLJS/zMQ3JBFH3v37sW4ceNw5MgR7N69G4WFhejduzeys7O19hs9ejTS09M1y7x58/Q6D7vniIiISFZqSFAbMC5J37I7duzQeh0bG4tatWrh+PHj6NKli2a9ra0tPD09yx0XW5qIiIjIJGVmZmot+fn5OpW7d+8eAMDFxUVr/erVq+Hm5obmzZtj2rRpyMnJ0SsetjQRERGRrOSaEdzHx0dr/axZsxAVFVVqWbVajbfeegsdO3ZE8+bNNetfeukl+Pr6wtvbG6dPn8bUqVORmJiIjRs36hwXkyYiIiKSVXnGJT1aHgAuX74MpVKpWW9tbV1m2XHjxuHPP//EgQMHtNaPGTNG83OLFi3g5eWFnj17IiUlBQ0aNNApLiZNREREZJKUSqVW0lSWiIgIbN26Ffv27UOdOnVK3bd9+/YAgOTkZCZNREREZBxqGPjsOT0Hggsh8Oabb2LTpk2Ii4uDn59fmWUSEhIAAF5eXjqfh0kTERERyUoYePec0LPsuHHjsGbNGvz4449wcHDAtWvXAACOjo6wsbFBSkoK1qxZg2effRaurq44ffo0Jk6ciC5duiAwMFDn8zBpIiIiIlmphYEtTXqWXb58OYDiCSwfFhMTg/DwcFhZWeGXX37BokWLkJ2dDR8fHwwePBjvvfeeXudh0kRERERVmhClP3fFx8cHe/fuNfg8TJqIiIhIVnLdPWdqmDQRERGRrCq7e66ymGYqR0RERGRi2NJEREREsqrsZ89VFiZNREREJCt2zxERERHVYGxpIiIiIllV15YmJk1EREQkq+qaNLF7joiIiEgHbGmSQXh4ODIyMrB582Zjh1Kj9Au/hRdevwEX9yJcPGuDz96rjcQEW2OHZRxrMiEdyAEuFQHWEtDUGmKMI+BjqdlFWnAHOJEH3FYDNhLQzApitBNQ1/LJx61BeD2VjXVUtuZPZeKF0VfRsFkWXD0K8f5rATj8i4uxw6p0bGkyQVFRUWjVqpVsx+vWrRveeustvcstXrwYsbGxssVRkeLi4iBJEjIyMowdikG6Pn8XY2ZdxeoFnhgX0ggXzyowZ81FOLoWGjs0o5BO50M87wDxqQfEPHdAJSBNuQnkqjX7iEZWEFNcIGI8IT5yBwQgTb0JqEp//EBNwOupbKwj3ShsVLh4zhafRfkZOxSjEvh32oHyLKb6V6lKJ01yKSgoMKi8o6MjnJyc5AmGdDJozC3sWOOCXetdcClJgSVT6yA/V0LIsDvGDs0oxEfuQKgdUM8SaFCcHEk3VEDSQ9d2X3sgUAF4WgCNrCBGOhbvc11lvMBNBK+nsrGOdHNsnzNWLayLQ7tdjR2KUT1oaTJkMUVGTZrUajXmzp0LPz8/2NjYoGXLlvjhhx8A/NsismfPHrRr1w62trZ45plnkJiYCACIjY1FdHQ0Tp06BUmSIEmSprUnIyMDr776Ktzd3aFUKtGjRw+cOnVKc94HLVRfffUV/Pz8oFAoEB4ejr1792Lx4sWa46WlpUGlUmHUqFGaGAMCArB48WKt9xEeHo4BAwZoXnfr1g3jx4/HlClT4OLiAk9PT0RFRWmVkSQJX3zxBfr27QtbW1s0adIEhw8fRnJyMrp16wY7Ozs888wzSElJ0Sr3448/ok2bNlAoFKhfvz6io6NRVFSkddyvvvoKAwcOhK2tLfz9/bFlyxYAQFpaGrp37w4AcHZ2hiRJCA8PL/f/n7FYWKrhH5iDE/sdNOuEkHByvwOats0xYmQmJPufFiaHJ/yK56oh7cyG8DIH3M0rLy4TxOupbKwjomJGTZrmzp2LVatW4fPPP8eZM2cwceJEvPzyy1pPIp4+fTrmz5+PY8eOwcLCAq+88goAYOjQoXj77bfRrFkzpKenIz09HUOHDgUA/Oc//8GNGzewfft2HD9+HG3atEHPnj1x586/34iSk5OxYcMGbNy4EQkJCVi8eDGCgoIwevRozfF8fHygVqtRp04dfP/99zh79ixmzpyJd999F999912p723lypWws7NDfHw85s2bh/fffx+7d+/W2mf27NkYMWIEEhIS0LhxY7z00ksYO3Yspk2bhmPHjkEIgYiICM3++/fvx4gRIzBhwgScPXsWX3zxBWJjYzFnzhyt40ZHR2PIkCE4ffo0nn32WQwfPhx37tyBj48PNmzYAABITExEenp6iQTwgfz8fGRmZmotpkLpooK5BZBxU3tI3t1bFnB2L3pCqRpELSAty4BobgX4WWlv+/E+pOeuwKzv38DveRDzagGWpvmNrrLweiob64j0VV1bmow2EDw/Px8ffvghfvnlFwQFBQEA6tevjwMHDuCLL77AmDFjAABz5sxB165dAQDvvPMOnnvuOeTl5cHGxgb29vawsLCAp6en5rgHDhzA77//jhs3bsDa2hoA8L///Q+bN2/GDz/8oDluQUEBVq1aBXd3d01ZKysr2Nraah3P3Nwc0dHRmtd+fn44fPgwvvvuOwwZMuSJ7y8wMBCzZs0CAPj7++PTTz/Fnj170KtXL80+I0eO1Bxj6tSpCAoKwowZMxASEgIAmDBhAkaOHKnZPzo6Gu+88w7CwsI09TV79mxMmTJFcy6guOVr2LBhAIAPP/wQS5Yswe+//47Q0FC4uBQPSKxVq1apXYpz587Vet9UdUhL7gJphRCLa5Xc2NMOoq0C4o4K0nf3Ib1/C2KJB2Blmn+giKhqqq4DwY2WNCUnJyMnJ0criQCKk5nWrVtrXgcGBmp+9vLyAgDcuHEDdevWfexxT506haysLLi6avcn5+bmanV1+fr6aiVMpVm2bBm++eYbXLp0Cbm5uSgoKChzAPrDcT+I/caNG0/cx8PDAwDQokULrXV5eXnIzMyEUqnEqVOncPDgQa2WJZVKhby8POTk5MDW1rbEce3s7KBUKkucuyzTpk3DpEmTNK8zMzPh4+Oj1zEqSuYdc6iKAKdHvuE6uxXh7s2afUOotOQucCQPYmEtwP0xdWFvVrzUsYRoYg1pwN/AgRygh13lB2sieD2VjXVEVMxoV3tWVhYA4Oeff0bt2rW1tllbW2sSHEvLh26ZloozT7VajSfJysqCl5cX4uLiSmx7uGXFzk63D4l169YhMjIS8+fPR1BQEBwcHPDJJ58gPj6+1HIPx/0g9kfjftx7K+39ZmVlITo6GoMGDSpxPoVCode5y2Jtba1pqTM1RYVmSDpti9ad7uPwDkcAgCQJtOqUhS2xNXTwpRCQlmYAB3IhFrgDXjr8aot/FsPug6jyeD2VjXVE+mJLk8yaNm0Ka2trXLp0SdP99rBHB0A/jpWVFVQq7Tt/2rRpg2vXrsHCwgL16tXTK6bHHe/gwYN45pln8MYbb+gVW0Vo06YNEhMT0bBhw3Ifw8qqeIzLo++zqtn4pRsiF13GhVO2SDxpi4Gjb0Jhq8audTVvPhTgnxamPTkQs90AWzPgzj//v3YSYG0GXC0C4nKAdgrA0Qy4pYK0NrO4W669ovSD1wC8nsrGOtKNwlYFb988zWsPnzzUb5KN+xkWuJluml9EK4IQEoQBiY8hZSuS0ZImBwcHREZGYuLEiVCr1ejUqRPu3buHgwcPQqlUwtfXt8xj1KtXD6mpqUhISECdOnXg4OCA4OBgBAUFYcCAAZg3bx4aNWqEq1ev4ueff8bAgQPRrl27Uo8XHx+PtLQ02Nvbw8XFBf7+/li1ahV27twJPz8/fPvttzh69Cj8/Cp/Do6ZM2eib9++qFu3Ll544QWYmZnh1KlT+PPPP/HBBx/odAxfX19IkoStW7fi2Wef1YwNq2r2bnGGo6sKIyZfg7N7ES6escH04X7IuFUzJ2qUtmQX/zvpptZ69WSX4qkIrCRIf+QDG+4DWWrA2RwItIZYWqv45xqO11PZWEe68W+RhXmrz2pej53+FwBg9wZ3LJha/i+8ZBqM2hk9e/ZsuLu7Y+7cubh48SKcnJzQpk0bvPvuuzp1Jw0ePBgbN25E9+7dkZGRgZiYGISHh2Pbtm2YPn06Ro4ciZs3b8LT0xNdunTRjBt6ksjISISFhaFp06bIzc1Famoqxo4di5MnT2Lo0KGQJAnDhg3DG2+8ge3bt8tVDToLCQnB1q1b8f777+Pjjz+GpaUlGjdujFdffVXnY9SuXVszoHzkyJEYMWJElZmY81FbYtywJcbN2GGYBPWeMsabuZlDzNVtDF9NxeupbKyjsv0R74g+DYOMHYbRPZik0pDypkgSQpjqxJtkQjIzM+Ho6Ihu6A8Lid8sS1NmAkMAALOel40dAlUjZrZ8nEtZikQBfs1Zh3v37kGpVFbIOR58VrTfPB4WduXvjizKzkf8gCUVGmt5cEZwIiIiIh3wXlEiIiKSFQeCExEREemAUw4QERER6aC6tjRxTBMRERGRDtjSRERERLISBnbPmWpLE5MmIiIikpUAYMiERqY6FxK754iIiIh0wJYmIiIikpUaEqRqOCM4kyYiIiKSFe+eIyIiIqrB2NJEREREslILCRIntyQiIiIqnRAG3j1norfPsXuOiIiISAdsaSIiIiJZVdeB4EyaiIiISFZMmoiIiIh0UF0HgnNMExEREZEO2NJEREREsqqud88xaSIiIiJZFSdNhoxpkjEYGbF7joiIiEgHbGkiIiIiWfHuOSIiIiIdiH8WQ8qbInbPEREREemASRMRERHJ6kH3nCGLPubOnYunnnoKDg4OqFWrFgYMGIDExEStffLy8jBu3Di4urrC3t4egwcPxvXr1/U6D5MmIiIikpeQYdHD3r17MW7cOBw5cgS7d+9GYWEhevfujezsbM0+EydOxE8//YTvv/8ee/fuxdWrVzFo0CC9zsMxTURERCQvAweCQ8+yO3bs0HodGxuLWrVq4fjx4+jSpQvu3buHr7/+GmvWrEGPHj0AADExMWjSpAmOHDmCDh066HQetjQRERGRScrMzNRa8vPzdSp37949AICLiwsA4Pjx4ygsLERwcLBmn8aNG6Nu3bo4fPiwzvEwaSIiIiJZPZgR3JAFAHx8fODo6KhZ5s6dW+a51Wo13nrrLXTs2BHNmzcHAFy7dg1WVlZwcnLS2tfDwwPXrl3T+X2xe46IiIhkJdc8TZcvX4ZSqdSst7a2LrPsuHHj8Oeff+LAgQPlPv+TMGkikplZz8vGDqFKqHPE3tghVAlXOmQZOwQio1EqlVpJU1kiIiKwdetW7Nu3D3Xq1NGs9/T0REFBATIyMrRam65fvw5PT0+dj8/uOSIiIpKXkAxf9DmdEIiIiMCmTZvw66+/ws/PT2t727ZtYWlpiT179mjWJSYm4tKlSwgKCtL5PGxpIiIiIlk9PC6pvOX1MW7cOKxZswY//vgjHBwcNOOUHB0dYWNjA0dHR4waNQqTJk2Ci4sLlEol3nzzTQQFBel85xzApImIiIiquOXLlwMAunXrprU+JiYG4eHhAICFCxfCzMwMgwcPRn5+PkJCQvDZZ5/pdR4mTURERCSvSn74nNChaUqhUGDZsmVYtmxZOYNi0kREREQyk+vuOVOjU9K0ZcsWnQ/4/PPPlzsYIiIiIlOlU9I0YMAAnQ4mSRJUKpUh8RAREVF1YEj3nInSKWlSq9UVHQcRERFVE9W1e86geZry8vLkioOIiIiqCyHDYoL0TppUKhVmz56N2rVrw97eHhcvXgQAzJgxA19//bXsARIRERGZAr2Tpjlz5iA2Nhbz5s2DlZWVZn3z5s3x1VdfyRocERERVUWSDIvp0TtpWrVqFb788ksMHz4c5ubmmvUtW7bE+fPnZQ2OiIiIqiB2zxX7+++/0bBhwxLr1Wo1CgsLZQmKiIiIyNTonTQ1bdoU+/fvL7H+hx9+QOvWrWUJioiIiKqwatrSpPeM4DNnzkRYWBj+/vtvqNVqbNy4EYmJiVi1ahW2bt1aETESERFRVSKk4sWQ8iZI75am/v3746effsIvv/wCOzs7zJw5E+fOncNPP/2EXr16VUSMREREREZXrmfPde7cGbt375Y7FiIiIqoGhCheDClvisr9wN5jx47h3LlzAIrHObVt21a2oIiIiKgKM3RcUnVJmq5cuYJhw4bh4MGDcHJyAgBkZGTgmWeewbp161CnTh25YyQiIiIyOr3HNL366qsoLCzEuXPncOfOHdy5cwfnzp2DWq3Gq6++WhExEhERUVXyYCC4IYsJ0rulae/evTh06BACAgI06wICArB06VJ07txZ1uCIiIio6pFE8WJIeVOkd9Lk4+Pz2EksVSoVvL29ZQmKiIiIqrBqOqZJ7+65Tz75BG+++SaOHTumWXfs2DFMmDAB//vf/2QNjoiIiMhU6NTS5OzsDEn6t38xOzsb7du3h4VFcfGioiJYWFjglVdewYABAyokUCIiIqoiqunkljolTYsWLargMIiIiKjaqKbdczolTWFhYRUdBxEREZFJK/fklgCQl5eHgoICrXVKpdKggIiIiKiKq6YtTXoPBM/OzkZERARq1aoFOzs7ODs7ay1ERERUwwkZFhOkd9I0ZcoU/Prrr1i+fDmsra3x1VdfITo6Gt7e3li1alVFxEhERERkdHp3z/30009YtWoVunXrhpEjR6Jz585o2LAhfH19sXr1agwfPrwi4iQiIqKqoprePad3S9OdO3dQv359AMXjl+7cuQMA6NSpE/bt2ydvdERERFTlPJgR3JDFFOmdNNWvXx+pqakAgMaNG+O7774DUNwC9eABvqS/2NhYrfqLiopCq1atSi2TlpYGSZKQkJBQobGZqn7ht7Ay/ix+ungai7cmIaBVjrFDMkmsp39lrizA9ZE5+LtHFq72ycatKbko/Euttc+N13NwpUOW1nL34zwjRWxaeC2VrflTmYj68jz+7+AxbE8+jKDgO8YOiWSkd9I0cuRInDp1CgDwzjvvYNmyZVAoFJg4cSImT54se4A1VWRkJPbs2aN5HR4eXmLiUB8fH6Snp6N58+aVHJ3xdX3+LsbMuorVCzwxLqQRLp5VYM6ai3B0LfmIn5qM9aQt/6QK9oMtUesrG7gtUQBFwK0JuVDnan+ttetvAa+fbTWLY4S1kSI2HbyWdKOwUeHiOVt8FuVn7FCMq5oOBNd7TNPEiRM1PwcHB+P8+fM4fvw4GjZsiMDAQFmDq8ns7e1hb29f6j7m5ubw9PSspIhMy6Axt7BjjQt2rXcBACyZWgdP98xEyLA7+O5TDyNHZzpYT9rcF9lovXaeoUB6n2wUnlfDurW5Zr2kkGDuqvd3ymqN15Juju1zxrF9vJO8ujL4r4Kvry8GDRpU4xOmbt26ISIiAhEREXB0dISbmxtmzJgBIYrT5bt372LEiBFwdnaGra0t+vTpg6SkpCce7+HuuaioKKxcuRI//vgjJEmCJEmIi4t7bPfcmTNn0LdvXyiVSjg4OKBz585ISUkBAMTFxeHpp5+GnZ0dnJyc0LFjR/z1118VVicVxcJSDf/AHJzY76BZJ4SEk/sd0LQtuwseYD2VTWQV/36aPTK9XM7OQlwNycK1l3Jw77N8qPNM9GtvJeG1RPqSYOCYJmO/gSfQqaVpyZIlOh9w/Pjx5Q6mqlu5ciVGjRqF33//HceOHcOYMWNQt25djB49GuHh4UhKSsKWLVugVCoxdepUPPvsszh79iwsLS1LPW5kZCTOnTuHzMxMxMTEAABcXFxw9epVrf3+/vtvdOnSBd26dcOvv/4KpVKJgwcPoqioCEVFRRgwYABGjx6NtWvXoqCgAL///rvWMwUflp+fj/z8fM3rzMxMA2tHPkoXFcwtgIyb2pfv3VsW8GmY/4RSNQ/rqXRCLZCxKB9WgWawbPBvK5NtiCUsPCWYu0koTFbj3rICFP6lhtvHNqUcrXrjtURUTKekaeHChTodTJKkGp00+fj4YOHChZAkCQEBAfjjjz+wcOFCdOvWDVu2bMHBgwfxzDPPAABWr14NHx8fbN68Gf/5z39KPa69vT1sbGyQn59fanfcsmXL4OjoiHXr1mkSsUaNGgEovuvx3r176Nu3Lxo0aAAAaNKkyROPNXfuXERHR+v1/omqkoxP8lGYoob7l9rJkP2Af7/EWDY0h5mbhFsReSi6ooZFHXbZEemkmk45oFPS9OBuOSpdhw4dtFpugoKCMH/+fJw9exYWFhZo3769ZpurqysCAgJw7tw52c6fkJCAzp07P7blysXFBeHh4QgJCUGvXr0QHByMIUOGwMvL67HHmjZtGiZNmqR5nZmZCR8fH9liNUTmHXOoigAn9yKt9c5uRbh706AnA1UrrKcnu/u/fOQdVMH9cxtY1Co9EbJqVtwKVZOTJl5LpDc+RoVMnY1N6d0HMTExOHz4MJ555hmsX78ejRo1wpEjRx67r7W1NZRKpdZiKooKzZB02hatO93XrJMkgVadsnD2uK0RIzMtrKeShBC4+7985O4tgtunNrDwLvtPYOGF4ikJzFxN85tvZeC1RFSMSZOM4uPjtV4fOXIE/v7+aNq0KYqKirS23759G4mJiWjatKlOx7aysoJKpSp1n8DAQOzfvx+FhU++Bbh169aYNm0aDh06hObNm2PNmjU6nd/UbPzSDX1euoPg/9yBT8M8vPnRFShs1di1zsXYoZkU1pO2jE/ykbOjEK7RCpjZAarbaqhuqyH+GehddEWNzG8KUHBehaKrauTuK8Kd9/Ng1doMVv7mZRy9euO1pBuFrQr1m2SjfpNsAICHTx7qN8mGu1cNG/vFKQeoLJcuXcKkSZMwduxYnDhxAkuXLsX8+fPh7++P/v37Y/To0fjiiy/g4OCAd955B7Vr10b//v11Ona9evWwc+dOJCYmwtXVFY6OjiX2iYiIwNKlS/Hiiy9i2rRpcHR0xJEjR/D000/DysoKX375JZ5//nl4e3sjMTERSUlJGDFihNzVUCn2bnGGo6sKIyZfg7N7ES6escH04X7IuFX6oPqahvWkLXtjcffSzTdytdY7v2cNu76WgCWQd7QIWesKoM4DLGpJsOlmAeUrVsYI16TwWtKNf4sszFt9VvN67PTiO5R3b3DHgqkNjRVWpTN0Vm9TnRGcSZOMRowYgdzcXDz99NMwNzfHhAkTMGbMGADFXWMTJkxA3759UVBQgC5dumDbtm1l3jn3wOjRoxEXF4d27dohKysLv/32G+rVq6e1j6urK3799VdMnjwZXbt2hbm5OVq1aoWOHTvC1tYW58+fx8qVK3H79m14eXlh3LhxGDt2rNzVUGm2xLhhS4ybscMweaynf9U5UvrcZxYeZqi1nN1NT8JrqWx/xDuiT8MgY4dBFUQSDyYSIoN069YNrVq1wqJFi4wdSoXIzMyEo6MjuqE/LCR+syTDlZXAULErHbKMHUKVYGbLZLcsRaIAv+asw7179ypsnOqDz4p6H8yBmUJR7uOo8/KQ9t70Co21PMo1pmn//v14+eWXERQUhL///hsA8O233+LAgQOyBkdERERVUDUd06R30rRhwwaEhITAxsYGJ0+e1EyAeO/ePXz44YeyB0hERERkCvROmj744AN8/vnnWLFihdZ4nI4dO+LEiROyBleVxMXFVduuOSIiIn0Y9AgVAweRVyS9B4InJiaiS5cuJdY7OjoiIyNDjpiIiIioKqumM4Lr3dLk6emJ5OTkEusPHDiA+vXryxIUERERVWEc01Rs9OjRmDBhAuLj4yFJEq5evYrVq1cjMjISr7/+ekXESERERGR0eidN77zzDl566SX07NkTWVlZ6NKlC1599VWMHTsWb775ZkXESERERFVIZY9p2rdvH/r16wdvb29IkoTNmzdrbQ8PD4ckSVpLaGio3u9L7zFNkiRh+vTpmDx5MpKTk5GVlYWmTZvC3p5zrhAREREq/YG92dnZaNmyJV555RUMGjTosfuEhoYiJiZG89ra2lrvsMo9I7iVlZXOz00jIiIiqih9+vRBnz59St3H2toanp6eBp1H76Spe/fukKQnj2r/9ddfDQqIiIiIqjhDpw34p2xmZqbWamtr63K1EAHFUwPVqlULzs7O6NGjBz744AO4urrqdQy9k6ZWrVppvS4sLERCQgL+/PNPhIWF6Xs4IiIiqm5k6p7z8fHRWj1r1ixERUXpfbjQ0FAMGjQIfn5+SElJwbvvvos+ffrg8OHDMDc31/k4eidNCxcufOz6qKgoZGXxGUlEREQkj8uXL2s9e668rUwvvvii5ucWLVogMDAQDRo0QFxcHHr27Knzccr17LnHefnll/HNN9/IdTgiIiKqqmSap0mpVGot5U2aHlW/fn24ubk9dt7J0pR7IPijDh8+DIUBTzQmIiKi6sHQR6FU9GNUrly5gtu3b8PLy0uvcnonTY/eyieEQHp6Oo4dO4YZM2boezgiIiIig2RlZWm1GqWmpiIhIQEuLi5wcXFBdHQ0Bg8eDE9PT6SkpGDKlClo2LAhQkJC9DqP3kmTo6Oj1mszMzMEBATg/fffR+/evfU9HBEREZFBjh07hu7du2teT5o0CQAQFhaG5cuX4/Tp01i5ciUyMjLg7e2N3r17Y/bs2Xp39+mVNKlUKowcORItWrSAs7OzXiciIiKiGqKSJ7fs1q0bhHhyoZ07dxoQzL/0Gghubm6O3r17IyMjQ5aTExERUfVT2Y9RqSx63z3XvHlzXLx4sSJiISIiIjJZeidNH3zwASIjI7F161akp6cjMzNTayEiIiIydLoBU6TzmKb3338fb7/9Np599lkAwPPPP6/1OBUhBCRJgkqlkj9KIiIiqjoqeUxTZdE5aYqOjsZrr72G3377rSLjISIiIjJJOidND0ald+3atcKCISIioqrP1Ce3LC+9phx4uDuOiIiI6LFqevccADRq1KjMxOnOnTsGBURERERkivRKmqKjo0vMCE5ERET0MHbPAXjxxRdRq1atioqFiIiIqoNq2j2n8zxNHM9ERERENZned88RERERlaqatjTpnDSp1eqKjIOIiIiqCY5pIiKS0ZUOWcYOoUrYeTXB2CFUCSHerYwdgslTi8LKO1k1bWnS+9lzRERERDURW5qIiIhIXtW0pYlJExEREcmquo5pYvccERERkQ7Y0kRERETyYvccERERUdnYPUdERERUg7GliYiIiOTF7jkiIiIiHVTTpIndc0REREQ6YEsTERERyUr6ZzGkvCli0kRERETyqqbdc0yaiIiISFaccoCIiIioBmNLExEREcmL3XNEREREOjLRxMcQ7J4jIiIi0gFbmoiIiEhW1XUgOJMmIiIiklc1HdPE7jkiIiIiHbCliYiIiGTF7jkiIiIiXbB7joiIiKjmYksTERERyYrdc0RERES6qKbdc0yaiIiISF7VNGnimCYiIiIiHbCliYiIiGTFMU1EREREumD3HBEREVHNxZYmIiIikpUkBCRR/uYiQ8pWJLY0UZXVL/wWVsafxU8XT2Px1iQEtMoxdkgmifWkG9bTv35a6YrXegZgYKMWGNioBd7q54+jvzpoti+eUgfhQU3Qr34ghjRvjlnhfriUZG3EiE0LryX82z1nyKKHffv2oV+/fvD29oYkSdi8ebN2OEJg5syZ8PLygo2NDYKDg5GUlKT322LSVANFRUWhVatWxg7DIF2fv4sxs65i9QJPjAtphItnFZiz5iIcXQuNHZpJYT3phvWkzd2rEK+8exWf7kjE0u0X0LLjfUSN9ENaogIA4B+Yi7cXXsKKvecxZ00KIIB3hzWASmXkwE0AryXjyM7ORsuWLbFs2bLHbp83bx6WLFmCzz//HPHx8bCzs0NISAjy8vL0Og+TphpECIGioiJjhyGLQWNuYccaF+xa74JLSQosmVoH+bkSQobdMXZoJoX1pBvWk7YOvTPxdM/7qF2/AHUa5GPkO9egsFPj/HFbAMCzL99Giw7Z8PQpgH9gLsKmpuPmVStcv2xl5MiNj9dSsQd3zxmy6KNPnz744IMPMHDgwBLbhBBYtGgR3nvvPfTv3x+BgYFYtWoVrl69WqJFqixMmozshx9+QIsWLWBjYwNXV1cEBwcjOzsb4eHhGDBgAKKjo+Hu7g6lUonXXnsNBQUFmrL5+fkYP348atWqBYVCgU6dOuHo0aOa7XFxcZAkCdu3b0fbtm1hbW2N//u//0N0dDROnToFSZIgSRJiY2ON8M7Lz8JSDf/AHJzY/293gRASTu53QNO2NbAZ/AlYT7phPZVOpQLiNjshP8cMTdpll9iel2OGXetd4Fk3H+7eNbs1hdfSQ2TqnsvMzNRa8vPz9Q4lNTUV165dQ3BwsGado6Mj2rdvj8OHD+t1LA4EN6L09HQMGzYM8+bNw8CBA3H//n3s378f4p8BcHv27IFCoUBcXBzS0tIwcuRIuLq6Ys6cOQCAKVOmYMOGDVi5ciV8fX0xb948hISEIDk5GS4uLprzvPPOO/jf//6H+vXrQ6FQ4O2338aOHTvwyy+/ACi+eB6Vn5+vdXFmZmZWZFXoRemigrkFkHFT+/K9e8sCPg31/4WqrlhPumE9PV7qOQXe6uePgnwz2NipMfPrVPg2+rc+fop1xVcfeCMvxxx1GuRh7roUWFqZ5uDdysJrSX4+Pj5ar2fNmoWoqCi9jnHt2jUAgIeHh9Z6Dw8PzTZdMWkyovT0dBQVFWHQoEHw9fUFALRo0UKz3crKCt988w1sbW3RrFkzvP/++5g8eTJmz56N3NxcLF++HLGxsejTpw8AYMWKFdi9eze+/vprTJ48WXOc999/H7169dK8tre3h4WFBTw9PZ8Y29y5cxEdHS33WyaiKqJOg3x8tjsROffNsX+rE/43wRefbEzSJE49Bt1Fmy73ceeGJX5YXgtzxtbDwh+TYKWo2YkTFZNrcsvLly9DqVRq1ltbG/eGA3bPGVHLli3Rs2dPtGjRAv/5z3+wYsUK3L17V2u7ra2t5nVQUBCysrJw+fJlpKSkoLCwEB07dtRst7S0xNNPP41z585pnaddu3Z6xzZt2jTcu3dPs1y+fLkc77BiZN4xh6oIcHLXHp/l7FaEuzf5PeAB1pNuWE+PZ2klUNuveMzSK++mw69pLjZ/5a7ZbqdUo3b9ArTokI33VqThcrI1Dm4v2Wpdk/BaeohM3XNKpVJrKU/S9KCB4Pr161rrr1+/XmrjweMwaTIic3Nz7N69G9u3b0fTpk2xdOlSBAQEIDU1Vdbz2NnZ6V3G2tq6xMVqKooKzZB02hatO93XrJMkgVadsnD2uG0pJWsW1pNuWE+6EQIoLHj8R4YQAIT0xO01Ba+lf1X2QPDS+Pn5wdPTE3v27NGsy8zMRHx8PIKCgvQ6Vg1LfU2PJEno2LEjOnbsiJkzZ8LX1xebNm0CAJw6dQq5ubmwsbEBABw5cgT29vbw8fGBm5sbrKyscPDgQU3XXmFhIY4ePYq33nqr1HNaWVlBVcXvDd74pRsiF13GhVO2SDxpi4Gjb0Jhq8audS5lF65BWE+6YT1p++ZDLzzVIxPutQuRm2WG3zY54/Qhe8xZk4L0v6ywd4sT2na9D0eXItxMt8R3n3rAykaNp3uazthHY+G1ZBxZWVlITk7WvE5NTUVCQgJcXFxQt25dvPXWW/jggw/g7+8PPz8/zJgxA97e3hgwYIBe52HSZETx8fHYs2cPevfujVq1aiE+Ph43b95EkyZNcPr0aRQUFGDUqFF47733kJaWhlmzZiEiIgJmZmaws7PD66+/jsmTJ2suinnz5iEnJwejRo0q9bz16tXTXFB16tSBg4OD0fuJ9bV3izMcXVUYMfkanN2LcPGMDaYP90PGLUtjh2ZSWE+6YT1py7hlgU/G++LODQvYOqjg1yQPc9akoG3XLNy+ZoE/4+2xaYU7su6Zw8mtCC06ZGHhj0lwcqseU5oYgtfSPyr52XPHjh1D9+7dNa8nTZoEAAgLC0NsbCymTJmC7OxsjBkzBhkZGejUqRN27NgBhUKh13kkIUx0rvIa4Ny5c5g4cSJOnDiBzMxM+Pr64s0330RERATCw8ORkZGhmawrPz8fw4YNw9KlSzUJTl5eHqZMmYK1a9fi/v37aNeuHRYuXIinnnoKQPGUA927d8fdu3fh5OSkOW9+fj6GDx+OPXv2ICMjAzExMQgPDy811szMTDg6OqIb+sNCqmG//ERGtPNqgrFDqBJCvFsZOwSTVyQKEYcfce/evQobcvHgs6LtkDmwsNQvIXlYUWEejn83vUJjLQ8mTSbqQdKk78RbFYVJE5FxMGnSDZOmsjFpMhy754iIiEheQvxzh4AB5U0QkyYiIiKSlVzzNJkaJk0mqqo92oSIiKi6Y9JERERE8qrku+cqC5MmIiIikpWkLl4MKW+Kavb0rUREREQ6YksTERERyYvdc0RERERl491zRERERLqopvM0cUwTERERkQ7Y0kRERESyYvccERERkS6q6UBwds8RERER6YAtTURERCQrds8RERER6YJ3zxERERHVXGxpIiIiIlmxe46IiIhIF7x7joiIiKjmYksTERERyYrdc0RERES6UIvixZDyJohJExEREcmLY5qIiIiIai62NBEREZGsJBg4pkm2SOTFpImIiIjkxRnBiYiIiGoutjQRERGRrDjlABEREZEuePccERERUc3FliYiIiKSlSQEJAMGcxtStiIxaSK9mNnawEyyMnYYRDVGiHcrY4dQJaj3+Bg7BJOnzs4H+lXWyf5ZDClvgtg9R0RERKQDtjQRERGRrNg9R0RERKSLanr3HJMmIiIikhdnBCciIiKqudjSRERERLLijOBEREREumD3HBEREVHNxZYmIiIikpWkLl4MKW+KmDQRERGRvNg9R0RERFRzsaWJiIiI5MXJLYmIiIjKVl0fo8LuOSIiIqrSoqKiIEmS1tK4cWPZz8OWJiIiIpKXEQaCN2vWDL/88ovmtYWF/CkOkyYiIiKSlwBgyLQB5ci3LCws4OnpacBJy8buOSIiIpLVgzFNhiwAkJmZqbXk5+c/8ZxJSUnw9vZG/fr1MXz4cFy6dEn298WkiYiIiEySj48PHB0dNcvcuXMfu1/79u0RGxuLHTt2YPny5UhNTUXnzp1x//59WeNh9xwRERHJS8DAMU3F/1y+fBlKpVKz2tra+rG79+nTR/NzYGAg2rdvD19fX3z33XcYNWpU+eN4BJMmIiIikpdMA8GVSqVW0qQrJycnNGrUCMnJyeWP4THYPUdERETVSlZWFlJSUuDl5SXrcZk0ERERkbzUMix6iIyMxN69e5GWloZDhw5h4MCBMDc3x7Bhw+R5P/9g9xwRERHJqrJnBL9y5QqGDRuG27dvw93dHZ06dcKRI0fg7u5e7hgeh0kTERERVWnr1q2rlPMwaSIiIiJ5GWFG8MrApImIiIjkVU2TJg4EJyIiItIBW5qIiIhIXtW0pYlJExEREclLDUAysLwJYtJEREREsqrsKQcqC8c0EREREemALU01QFpaGvz8/HDy5Em0atXK2OEYrPlTmXhh9FU0bJYFV49CvP9aAA7/4mLssEwO60k3rCfd9Qu/hRdevwEX9yJcPGuDz96rjcQEW2OHZTxrMiEdyAEuFQHWEtDUGmKMI+BjqdlFWnAHOJEH3FYDNhLQzApitBNQ1/LJx60OqumYJrY0maBu3brhrbfeMnYYJktho8LFc7b4LMrP2KGYNNaTblhPuun6/F2MmXUVqxd4YlxII1w8q8CcNRfh6Fpo7NCMRjqdD/G8A8SnHhDz3AGVgDTlJpD774Ac0cgKYooLRIwnxEfugACkqTcBlWkmBbJRC8MXE8SWJqpyju1zxrF9zsYOw+SxnnTDetLNoDG3sGONC3atL26FWzK1Dp7umYmQYXfw3aceRo7OOMRH2o/oEFNcYDb4KkRSARCoKF7Z1/7fHTwBMdIRZmOuQ1xXAd78CK5q2NJkYsLDw7F3714sXrwYkiRBkiSkpaXhzz//RJ8+fWBvbw8PDw/897//xa1btzTl1Go15s2bh4YNG8La2hp169bFnDlztI598eJFdO/eHba2tmjZsiUOHz5c2W+PiKogC0s1/ANzcGK/g2adEBJO7ndA07Y5RozMxGT/08Lk8ISP1lw1pJ3ZEF7mgLt55cVlDA+65wxZTBCTJhOzePFiBAUFYfTo0UhPT0d6ejocHBzQo0cPtG7dGseOHcOOHTtw/fp1DBkyRFNu2rRp+OijjzBjxgycPXsWa9asgYeH9re/6dOnIzIyEgkJCWjUqBGGDRuGoqKix8aRn5+PzMxMrYWIaialiwrmFkDGTe2Wkbu3LODs/vi/ITWOWkBalgHR3Arws9Le9uN9SM9dgVnfv4Hf8yDm1QIsDbkfvyowNGEyzaSJbYMmxtHREVZWVrC1tYWnpycA4IMPPkDr1q3x4Ycfavb75ptv4OPjgwsXLsDLywuLFy/Gp59+irCwMABAgwYN0KlTJ61jR0ZG4rnnngMAREdHo1mzZkhOTkbjxo1LxDF37lxER0dX1NskIqpWpCV3gbRCiMW1Sm7saQfRVgFxRwXpu/uQ3r8FscQDsKruiVP1w5amKuDUqVP47bffYG9vr1keJDopKSk4d+4c8vPz0bNnz1KPExgYqPnZy8sLAHDjxo3H7jtt2jTcu3dPs1y+fFmmd0NEVU3mHXOoigCnR1qVnN2KcPcmv3tLS+4CR/Ig5tcC3B9TH/ZmQB1LIFABMcsNuFwEHKjm3ZrVtHuOV3sVkJWVhX79+uHjjz8usc3LywsXL17U6TiWlg/dBisVf8NRqx8/7aq1tTWsra3LES0RVTdFhWZIOm2L1p3u4/AORwCAJAm06pSFLbGuRo7OiISAtDQDOJALscAd8NLhI/VBz1NBBcdmbGoDu9h49xzpysrKCiqVSvO6TZs22LBhA+rVqwcLi5L/Zf7+/rCxscGePXvw6quvVmaoRqGwVcHbN0/z2sMnD/WbZON+hgVupjPRe4D1pBvWk242fumGyEWXceGULRJP2mLg6JtQ2Kqxa13NndNKWnIX2JMDMdsNsDUD7vzzd9tOAqzNgKtFQFwO0E4BOJoBt1SQ1mYWd8u1Vxg3eCoXJk0mqF69eoiPj0daWhrs7e0xbtw4rFixAsOGDcOUKVPg4uKC5ORkrFu3Dl999RUUCgWmTp2KKVOmwMrKCh07dsTNmzdx5swZjBo1ythvR3b+LbIwb/VZzeux0/8CAOze4I4FUxsaKyyTw3rSDetJN3u3OMPRVYURk6/B2b0IF8/YYPpwP2TcquaTNJZC2pJd/O+km1rr1ZNdgFA7wEqC9Ec+sOE+kKUGnM2BQGuIpbWKf67OhLp4MaS8CWLSZIIiIyMRFhaGpk2bIjc3F6mpqTh48CCmTp2K3r17Iz8/H76+vggNDYWZWfGwtBkzZsDCwgIzZ87E1atX4eXlhddee83I76Ri/BHviD4Ng4wdhsljPemG9aS7LTFu2BLjZuwwTIZ6j0/pO7iZQ8x1L32f6qqazgguCWGikZFJyczMhKOjI3rYvggLyarsAkQkC3VONR8wLJMyExhCUXY+9vX7DPfu3YNSqayQczz4rAiu/RoszMrfvV2kzscvf39eobGWB++eIyIiItIBu+eIiIhIXtW0e45JExEREclLwMCkSbZIZMXuOSIiIiIdsKWJiIiI5MXuOSIiIiIdqNUADJhr6QlPqzA2ds8RERER6YAtTURERCQvds8RERER6aCaJk3sniMiIiLSAVuaiIiISF5qAYMmW1KbZksTkyYiIiKSlRBqCFH+O+AMKVuRmDQRERGRvIQwrLWIY5qIiIiIqi62NBEREZG8hIFjmky0pYlJExEREclLrQYkA8YlmeiYJnbPEREREemALU1EREQkL3bPEREREZVNqNUQBnTPmeqUA+yeIyIiItIBW5qIiIhIXuyeIyIiItKBWgBS9Uua2D1HREREpAO2NBEREZG8hABgyDxNptnSxKSJiIiIZCXUAsKA7jnBpImIiIhqBKGGYS1NnHKAiIiIqMIsW7YM9erVg0KhQPv27fH777/LenwmTURERCQroRYGL/pav349Jk2ahFmzZuHEiRNo2bIlQkJCcOPGDdneF5MmIiIikpdQG77oacGCBRg9ejRGjhyJpk2b4vPPP4etrS2++eYb2d4WxzSRTh4MyisShUaOhKhmUfN3Tifq7Hxjh2DyinIKAFTOIOsiFBo0t2URiq/7zMxMrfXW1tawtrYusX9BQQGOHz+OadOmadaZmZkhODgYhw8fLn8gj2DSRDq5f/8+AGBf7gYjR0JE9Bj9jB1A1XH//n04OjpWyLGtrKzg6emJA9e2GXwse3t7+Pj4aK2bNWsWoqKiSux769YtqFQqeHh4aK338PDA+fPnDY7lASZNpBNvb29cvnwZDg4OkCTJ2OEAKP4G4uPjg8uXL0OpVBo7HJPFetIN60k3rCfdmGI9CSFw//59eHt7V9g5FAoFUlNTUVBQYPCxhBAlPm8e18pUmZg0kU7MzMxQp04dY4fxWEql0mT+KJky1pNuWE+6YT3pxtTqqaJamB6mUCigUCgq/DwPc3Nzg7m5Oa5fv661/vr16/D09JTtPBwITkRERFWalZUV2rZtiz179mjWqdVq7NmzB0FBQbKdhy1NREREVOVNmjQJYWFhaNeuHZ5++mksWrQI2dnZGDlypGznYNJEVZa1tTVmzZpl9D5uU8d60g3rSTesJ92wnirf0KFDcfPmTcycORPXrl1Dq1atsGPHjhKDww0hCVN9wAsRERGRCeGYJiIiIiIdMGkiIiIi0gGTJiIiIiIdMGki2XTr1g1vvfVWhR1fkiRs3ry5wo5fE4SHh2PAgAHGDsOoYmNj4eTkpHkdFRWFVq1alVomLS0NkiQhISGhQmOjmoHXU9XFpImqjPT0dPTp08fYYZSLLh/M+ihvgrp48WLExsbKFkdFiouLgyRJyMjIqNDzREZGas3t8rjE0sfHB+np6WjevHmFxlKdyf07UJkq+gshVR2ccoCqDDlnda2qCgoKYGVlVe7ylTEbcFVjb28Pe3v7UvcxNzfn9VdOQgioVCpjh0EkD0Ekk65du4px48aJcePGCaVSKVxdXcV7770n1Gq1EEIIAGLTpk1aZRwdHUVMTIwQQoj8/Hwxbtw44enpKaytrUXdunXFhx9+qNn34fKpqakCgNiwYYPo1q2bsLGxEYGBgeLQoUNax9+/f7/o1KmTUCgUok6dOuLNN98UWVlZmu3Lli0TDRs2FNbW1qJWrVpi8ODBmm3ff/+9aN68uVAoFMLZ2Vk0aNBA+Pr6CoVCIQIDA8X3338vhBDit99+EwDEL7/8Itq2bStsbGxEUFCQOH/+vBBCiJiYGIHi531rlgfv+e7du2LUqFHCzc1NODg4iO7du4uEhARNDLNmzRItW7YUK1asEPXq1ROSJImwsLASx0tNTRVFRUXilVdeEfXq1RMKhUI0atRILFq0SKs+wsLCRP/+/bX+z958800xefJk4ezsLDw8PMSsWbO0ygAQn3/+uXjuueeEjY2NaNy4sTh06JBISkoSXbt2Fba2tiIoKEgkJydrldu8ebNo3bq1sLa2Fn5+fiIqKkoUFhZqHXfFihViwIABwsbGRjRs2FD8+OOPWv+/Dy9hYWE6XWd37twR//3vf4WTk5OwsbERoaGh4sKFC5rzxsTECEdHxxJ1/ODnR8/722+/aeI5efKkptyff/4pnnvuOeHg4CDs7e1Fp06dNHXw22+/iaeeekrY2toKR0dH8cwzz4i0tDRhKh6+tl1cXETPnj1FVlaW5vqIiorSXJNjx44V+fn5mrJ5eXnizTffFO7u7sLa2lp07NhR/P7775rtD34ftm3bJtq0aSMsLS1L/R0wdU/6ffvjjz9EaGiosLOzE7Vq1RIvv/yyuHnzpqacSqUSH3/8sWjQoIGwsrISPj4+4oMPPhBC6P73i0wPkyaSTdeuXYW9vb2YMGGCOH/+vPi///s/YWtrK7788kshRNlJ0yeffCJ8fHzEvn37RFpamti/f79Ys2aNZt/HJU2NGzcWW7duFYmJieKFF14Qvr6+mg/m5ORkYWdnJxYuXCguXLggDh48KFq3bi3Cw8OFEEIcPXpUmJubizVr1oi0tDRx4sQJsXjxYiGEEFevXhUWFhZiwYIFIjU1VURERAgPDw+xadMmkZKSImJiYoS1tbWIi4vTfEi0b99exMXFiTNnzojOnTuLZ555RgghRE5Ojnj77bdFs2bNRHp6ukhPTxc5OTlCCCGCg4NFv379xNGjR8WFCxfE22+/LVxdXcXt27eFEMUf4nZ2diI0NFScOHFCnDp1SmRkZIigoCAxevRozfGKiopEQUGBmDlzpjh69Ki4ePGipv7Xr1+vqcPHJU1KpVJERUWJCxcuiJUrVwpJksSuXbu06r127dpi/fr1IjExUQwYMEDUq1dP9OjRQ+zYsUOcPXtWdOjQQYSGhmrK7Nu3TyiVShEbGytSUlLErl27RL169URUVJTWcevUqSPWrFkjkpKSxPjx44W9vb24ffu2KCoqEhs2bBAARGJiokhPTxcZGRk6XWfPP/+8aNKkidi3b59ISEgQISEhomHDhqKgoEAIUXrSdP/+fTFkyBARGhqqqdv8/PwSSdOVK1eEi4uLGDRokDh69KhITEwU33zzjTh//rwoLCwUjo6OIjIyUiQnJ4uzZ8+K2NhY8ddffz3296ayPXptnz59Wixbtkzcv39fhIWFCXt7ezF06FDx559/iq1btwp3d3fx7rvvasqPHz9eeHt7i23btokzZ86IsLAw4ezsrLlmH/w+BAYGil27donk5GRx5cqVJ/4OmLrH/b7dunVLuLu7i2nTpolz586JEydOiF69eonu3btryk2ZMkU4OzuL2NhYkZycLPbv3y9WrFghhNDt7xeZJiZNJJuuXbuKJk2aaL7xCyHE1KlTRZMmTYQQZSdNb775pujRo4dW+Yc9Lmn66quvNNvPnDkjAIhz584JIYQYNWqUGDNmjNYx9u/fL8zMzERubq7YsGGDUCqVIjMzs8S5jh8/LgCItLQ0kZeXJ2xtbUt8Cxw1apQYNmyYVkvTAz///LMAIHJzc4UQ2h/MD8eiVCpFXl6e1voGDRqIL774QlPO0tJS3LhxQ2ufrl27igkTJjy2nh42btw4rdazxyVNnTp10irz1FNPialTp2peAxDvvfee5vXhw4cFAPH1119r1q1du1YoFArN6549e2q1EgohxLfffiu8vLyeeNysrCwBQGzfvl0I8e+H7927d0u89yddZxcuXBAAxMGDBzXbbt26JWxsbMR3330nhCg9aXpcHQkhSiRN06ZNE35+fppE7GG3b98WAERcXFyJbabg4Wv7UWFhYcLFxUVkZ2dr1i1fvlzY29sLlUolsrKyhKWlpVi9erVme0FBgfD29hbz5s0TQvz7/7Z582atYz/ud6CqePT3bfbs2aJ3795a+1y+fFmT5GdmZgpra2tNkvQoXf5+kWnimCaSVYcOHSBJkuZ1UFAQ5s+fr9OYhvDwcPTq1QsBAQEIDQ1F37590bt371LLBAYGan728vICANy4cQONGzfGqVOncPr0aaxevVqzjxACarUaqamp6NWrF3x9fVG/fn2EhoYiNDQUAwcOhK2tLVq2bImePXuiRYsW6NChA3JyctCrVy+tcxcUFKB169ZlxlK3bt3Hxn7q1ClkZWXB1dVVa31ubi5SUlI0r319feHu7l5qPTywbNkyfPPNN7h06RJyc3NRUFBQ5uDbh+N+EPuNGzeeuM+DRxK0aNFCa11eXh4yMzOhVCpx6tQpHDx4EHPmzNHso1KpkJeXh5ycHNja2pY4rp2dHZRKZYlzP86TrrOzZ8/CwsIC7du312xzdXVFQEAAzp07V+ZxdZWQkIDOnTvD0tKyxDYXFxeEh4cjJCQEvXr1QnBwMIYMGaK5Jozt4Ws7JCQEvXv3xgsvvABnZ2fN9gf/P0Bx3WZlZeHy5cu4d+8eCgsL0bFjR812S0tLPP300yXqt127dpXzhozg1KlT+O233x47Fi4lJQUZGRnIz89Hz549Sz1OaX+/yDQxaaJKI0kSxCNP7SksLNT83KZNG6SmpmL79u345ZdfMGTIEAQHB+OHH3544jEf/tB68CGqVqsBAFlZWRg7dizGjx9folzdunVhZWWFEydOIC4uDrt27cLMmTMRFRWFo0ePwsnJCbt378ahQ4fwzTffAAAsLCywadMm+Pj4aI5jbW2tSXBKi+VxsrKy4OXlhbi4uBLbHr4l3s7O7onHeNi6desQGRmJ+fPnIygoCA4ODvjkk08QHx9farlHP/glSSoR9+PeW1l1Hx0djUGDBpU4n0Kh0OvcpsjGxqbU7TExMRg/fjx27NiB9evX47333sPu3bvRoUOHSorwyczNzTXX9q5du7B06VJMnz69zOtEX7pet1VRVlYW+vXrh48//rjENi8vL1y8eFGn4+j7N4OMj0kTyerRP7xHjhyBv78/zM3N4e7ujvT0dM22pKQk5OTkaO2vVCoxdOhQDB06FC+88AJCQ0Nx584duLi46B1LmzZtcPbsWTRs2PCJ+1hYWCA4OBjBwcGYNWsWnJyc8Ouvv2LQoEGQJAkdO3ZEYGAgVq9eDTMzM5w8eRLdu3fXOsbDrUJPYmVlVaK1rU2bNrh27RosLCxQr149vd7b44538OBBPPPMM3jjjTf0iq0itGnTBomJiaXWfVke3CX4uFbKJ11nTZs2RVFREeLj4/HMM88AAG7fvo3ExEQ0bdpU5/OW1TIaGBiIlStXorCw8LGtTQDQunVrtG7dGtOmTUNQUBDWrFljEkkTAM213bFjR8ycORO+vr7YtGkTgOJWlNzcXE1ieOTIEdjb28PHxwdubm6wsrLCwYMH4evrC6D4i8/Ro0fLvCVfl3o1VY/G3qZNG2zYsAH16tWDhUXJj1F/f3/Y2Nhgz549ePXVVyszVKpgnKeJZHXp0iVMmjQJiYmJWLt2LZYuXYoJEyYAAHr06IFPP/0UJ0+exLFjx/Daa69pfeAsWLAAa9euxfnz53HhwgV8//338PT01Gp10cfUqVNx6NAhREREICEhAUlJSfjxxx8REREBANi6dSuWLFmChIQE/PXXX1i1ahXUajUCAgIQHx+PDz/8EMeOHcPdu3fx3HPP4e7du/j777+RkpKCEydOYOnSpVi5cqVOsdSrVw+pqalISEjArVu3kJ+fj+DgYAQFBWHAgAHYtWsX0tLScOjQIUyfPh3Hjh0r83jx8fFIS0vDrVu3oFar4e/vj2PHjmHnzp24cOECZsyYgaNHj5ar7gw1c+ZMrFq1CtHR0Thz5gzOnTuHdevW4b333tP5GL6+vpAkCVu3bsXNmzeRlZWl2fak68zf3x/9+/fH6NGjceDAAZw6dQovv/wyateujf79++t03nr16uH06dNITEzErVu3tFpDH4iIiEBmZiZefPFFHDt2DElJSfj222+RmJiI1NRUTJs2DYcPH8Zff/2FXbt2ISkpCU2aNNH5vVekh6/tS5cuYePGjbh586YmvoKCAowaNQpnz57Ftm3bMGvWLERERMDMzAx2dnZ4/fXXMXnyZOzYsQNnz57F6NGjkZOTg1GjRpV63sf9DlQVj/6+jRs3Dnfu3MGwYcNw9OhRpKSkYOfOnRg5ciRUKhUUCgWmTp2KKVOmYNWqVUhJScGRI0fw9ddfG/utkIGYNJGsRowYgdzcXDz99NMYN24cJkyYgDFjxgAA5s+fDx8fH3Tu3BkvvfQSIiMjtcZOODg4YN68eWjXrh2eeuoppKWlYdu2bTAzK99lGhgYiL179+LChQvo3LkzWrdujZkzZ8Lb2xtAcRfYxo0b0aNHDzRp0gSff/451q5di2bNmkGpVGLfvn149tln0ahRI/zxxx8YPHgwfv75ZzRp0gShoaH4+eef4efnp1MsgwcPRmhoKLp37w53d3esXbsWkiRh27Zt6NKlC0aOHIlGjRrhxRdfxF9//aUZN/QkkZGRMDc3R9OmTeHu7o5Lly5h7NixGDRoEIYOHYr27dvj9u3bWq1OlSkkJARbt27Frl278NRTT6FDhw5YuHChpnVCF7Vr10Z0dDTeeecdeHh4aJJdoPTrLCYmBm3btkXfvn0RFBQEIQS2bdv2xBahR40ePRoBAQFo164d3N3dcfDgwRL7uLq64tdff0VWVha6du2Ktm3bYsWKFbC0tIStrS3Onz+PwYMHo1GjRhgzZgzGjRuHsWPH6vzeK9Kj1/Z7772H+fPnayaO7dmzJ/z9/dGlSxcMHToUzz//PKKiojTlP/roIwwePBj//e9/0aZNGyQnJ2Pnzp2aMVFP8rjfgari0d+3goICHDx4ECqVCr1790aLFi3w1ltvwcnJSfP3asaMGXj77bcxc+ZMNGnSBEOHDtVpvB6ZNkk8OsiEiMiEdevWDa1atcKiRYuMHUq1Ex4ejoyMDD6uiOgJ2NJEREREpAMmTUREREQ6YPccERERkQ7Y0kRERESkAyZNRERERDpg0kRERESkAyZNRERERDpg0kRERESkAyZNRFRlhIeHY8CAAZrX3bp1K/OZZxUhLi4OkiQhIyPjiftIkqTXJJFRUVFo1aqVQXGlpaVBkiQkJCQYdBwiejwmTURkkPDwcEiSBEmSYGVlhYYNG+L9999HUVFRhZ9748aNmD17tk776pLoEBGVpuTjmYmI9BQaGoqYmBjk5+dj27ZtGDduHCwtLTFt2rQS+xYUFMDKykqW87q4uMhyHCIiXbCliYgMZm1tDU9PT/j6+uL1119HcHAwtmzZAuDfLrU5c+bA29sbAQEBAIDLly9jyJAhcHJygouLC/r374+0tDTNMVUqFSZNmgQnJye4urpiypQpeHQu3ke75/Lz8zF16lT4+PjA2toaDRs2xNdff420tDR0794dAODs7AxJkhAeHg4AUKvVmDt3Lvz8/GBjY4OWLVvihx9+0DrPtm3b0KhRI9jY2KB79+5acepq6tSpaNSoEWxtbVG/fn3MmDEDhYWFJfb74osv4OPjA1tbWwwZMgT37t3T2v7VV1+hSZMmUCgUaNy4MT777DO9YyGi8mHSRESys7GxQUFBgeb1nj17kJiYiN27d2Pr1q0oLCxESEgIHBwcsH//fhw8eBD29vYIDQ3VlJs/fz5iY2PxzTff4MCBA7hz5w42bdpU6nlHjBiBtWvXYsmSJTh37hy++OIL2Nvbw8fHBxs2bAAAJCYmIj09HYsXLwYAzJ07F6tWrcLnn3+OM2fOYOLEiXj55Zexd+9eAMXJ3aBBg9CvXz8kJCTg1VdfxTvvvKN3nTg4OCA2NhZnz57F4sWLsWLFCixcuFBrn+TkZHz33Xf46aefsGPHDpw8eRJvvPGGZvvq1asxc+ZMzJkzB+fOncOHH36IGTNmYOXKlXrHQ0TlIIiIDBAWFib69+8vhBBCrVaL3bt3C2traxEZGanZ7uHhIfLz8zVlvv32WxEQECDUarVmXX5+vrCxsRE7d+4UQgjh5eUl5s2bp9leWFgo6tSpozmXEEJ07dpVTJgwQQghRGJiogAgdu/e/dg4f/vtNwFA3L17V7MuLy9P2NraikOHDmntO2rUKDFs2DAhhBDTpk0TTZs21do+derUEsd6FACxadOmJ27/5JNPRNu2bTWvZ82aJczNzcWVK1c067Zv3y7MzMxEenq6EEKIBg0aiDVr1mgdZ/bs2SIoKEgIIURqaqoAIE6ePPnE8xJR+XFMExEZbOvWrbC3t0dhYSHUajVeeuklREVFaba3aNFCaxzTqVOnkJycDAcHB63j5OXlISUlBffu3UN6ejrat2+v2WZhYYF27dqV6KJ7ICEhAebm5ujatavOcScnJyMnJwe9evXSWl9QUIDWrVsDAM6dO6cVBwAEBQXpfI4H1q9fjyVLliAlJQVZWVkoKiqCUqnU2qdu3bqoXbu21nnUajUSExPh4OCAlJQUjBo1CqNHj9bsU1RUBEdHR73jISL9MWkiIoN1794dy5cvh5WVFby9vWFhof2nxc7OTut1VlYW2rZti9WrV5c4lru7e7lisLGx0btMVlYWAODnn3/WSlaA4nFacjl8+DCGDx+O6OhohISEwNHREevWrcP8+fP1jnXFihUlkjhzc3PZYiWiJ2PSREQGs7OzQ8OGDXXev02bNli/fj1q1apVorXlAS8vL8THx6NLly4AiltUjh8/jjZt2jx2/xYtWkCtVmPv3r0IDg4usf1BS5dKpdKsa9q0KaytrXHp0qUntlA1adJEM6j9gSNHjpT9Jh9y6NAh+Pr6Yvr06Zp1f/31V4n9Ll26hKtXr8Lb21tzHjMzMwQEBMDDwwPe3t64ePEihg8frtf5iUgeHAhORJVu+PDhcHNzQ//+/bF//36kpqYiLi4O48ePx5UrVwAAEyZMwEcffYTNmzfj/PnzeOONN0qdY6levXoICwvDK6+8gs2bN2uO+d133wEAfH19IUkStm7dips3byIrKwsODg6IjIzExIkTsXLlSqSkpODEiRNYunSpZnD1a6+9hqSkJEyePBmJiYlYs2YNYmNj9Xq//v7+uHTpEtatW4eUlBQsWbLksYPaFQoFwsLCcOrUKezfvx/jx4/HkCFD4OnpCQCIjo7G3LlzsWTJEly4cAF//PEHYmJisGDBAr3iIaLyYdJERJXO1tYW+/btQ926dTFo0CA0adIEo0aNQl5enqbl6e2338Z///tfhIWFISgoCA4ODhg4cGCpx12+fDleeOEFvPHGG2jcuDFGjx6N7OxsAEDt2rURHR2Nd955Bx4eHoiIiAAAzJ49GzNmzMDcuXPRpEkThIaG4ueff4afnx+A4nFGGzZswObNm9GyZUt8/vnn+PDDD/V6v88//zwmTpyIiIgItGrVCocOHcKMGTNK7NewYUMMGjQIzz77LHr37o3AwECtKQVeffVVfPXVV4iJiUGLFi3QtWtXxMbGamIloooliSeNqiQiIiIiDbY0EREREemASRMRERGRDpg0EREREemASRMRERGRDpg0EREREemASRMRERGRDpg0EREREemASRMRERGRDpg0EREREemASRMRERGRDpg0EREREeng/wGRPXFxMTcMcAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Doc2Vec + Logistic Regression Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd1a983-7b15-4393-bfe1-416467c8aa70",
   "metadata": {},
   "source": [
    "#### Main Findings:\n",
    "\n",
    "1. ~96% accuracy on the predictions using Count2Vec.\n",
    "\n",
    "2. Higher vector_size (128) is works the best. It is able to capture more information and create patterns.\n",
    "\n",
    "3. Top models used dm = 0, meaning PV-DBOW worked better than PV-DM in this task.\n",
    "\n",
    "4. Increasing epochs to 60 helped the model learn better document embeddings.\n",
    "   \n",
    "5. A higher min_count (e.g., 2 or 3) showed slightly lower mean accuracy compared to min_count=1. Keeping all the words is working better for the model\n",
    "\n",
    "7. Small window size (2) is performing better than a larger one (5) which means immediate neighbors are more important to perdict the document class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a41321-46fd-4123-826a-611913a72eee",
   "metadata": {},
   "source": [
    "#### Task 3: Using BERT for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31cc573-9916-40f9-8775-c450b8100417",
   "metadata": {},
   "source": [
    "Repeating the same process for BERT using GS and 3-fold cross val to find best parameters after producing embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e61eb85-6c49-4c96-b73a-69cbe0cb7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import (BertTokenizer,BertForSequenceClassification,TrainingArguments,Trainer)\n",
    "\n",
    "df = pd.read_csv(\"BBC_news.csv\")\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42, stratify=df[\"Class\"])\n",
    "# map string labels to ints\n",
    "label_to_id = {lbl: i for i, lbl in enumerate(train_df[\"Class\"].unique())}\n",
    "train_df[\"label\"] = train_df[\"Class\"].map(label_to_id)\n",
    "\n",
    "X_train = train_df[\"Text\"].tolist()\n",
    "y_train = train_df[\"label\"].tolist()\n",
    "\n",
    "num_labels = len(label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "087c7d5b-faaf-4ac1-815d-d493a264716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float = 2e-5,\n",
    "        num_train_epochs: int = 3,\n",
    "        batch_size: int = 8,\n",
    "        max_length: int = 128,\n",
    "        model_name: str = \"bert-base-uncased\",\n",
    "    ):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_train_epochs = num_train_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_length\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        toks = self.tokenizer(\n",
    "            X,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"np\",\n",
    "        )\n",
    "        ds = Dataset.from_dict({\n",
    "            \"input_ids\": toks[\"input_ids\"].tolist(),\n",
    "            \"attention_mask\": toks[\"attention_mask\"].tolist(),\n",
    "            \"label\": y\n",
    "        })\n",
    "        ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "        self.model_ = BertForSequenceClassification.from_pretrained(\n",
    "            self.model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            output_dir=\"./tmp\",\n",
    "            learning_rate=self.learning_rate,\n",
    "            per_device_train_batch_size=self.batch_size,\n",
    "            per_device_eval_batch_size=self.batch_size,\n",
    "            num_train_epochs=self.num_train_epochs,\n",
    "            logging_steps=50,\n",
    "            logging_dir=None,\n",
    "            save_strategy=\"no\",\n",
    "           # evaluation_strategy=\"no\",\n",
    "            report_to=None,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.model_,\n",
    "            args=args,\n",
    "            train_dataset=ds,\n",
    "            tokenizer=self.tokenizer,\n",
    "        )\n",
    "        trainer.train()\n",
    "        self.trainer_ = trainer\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        toks = self.tokenizer(\n",
    "            X,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"np\",\n",
    "        )\n",
    "        ds = Dataset.from_dict({\n",
    "            \"input_ids\": toks[\"input_ids\"].tolist(),\n",
    "            \"attention_mask\": toks[\"attention_mask\"].tolist(),\n",
    "        })\n",
    "        ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "        preds = self.trainer_.predict(ds).predictions\n",
    "        return np.argmax(preds, axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return accuracy_score(y, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a23bc-f56a-4ff4-9b36-43005ebc2c0b",
   "metadata": {},
   "source": [
    "For the param grid for BERT, I checked with hyper-parameters such as:\n",
    "\n",
    "1. learning_rate: Controls the step size for updating model weights during fine-tuning. Tested values: 2×10⁻⁵, 3×10⁻⁵, 5×10⁻⁵\n",
    "2. batch_size : Number of examples processed in one go. Tested values: 2, 4, 6\n",
    "3. num_train_epochs: Number of iterations (epochs) over the corpus. Tested values: 2, 3, 4\n",
    "\n",
    "Others are set to default values such as max_length (used 128) that gives max tokens per example, model_name (I used \"bert-base-uncased\") which specifies pre-trained BERT variant loaded for tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45de22cf-42ad-4a20-97f1-3c3bb4f2e4e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.300800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.715100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=2e-05, num_train_epochs=2; total time=  20.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.751000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=2e-05, num_train_epochs=2; total time=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.339700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.751100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=2e-05, num_train_epochs=2; total time=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.752600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.275200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=2e-05, num_train_epochs=3; total time=  27.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.422400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.452600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.263900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=2e-05, num_train_epochs=3; total time=  27.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.402600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.827000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.450200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.245800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=2e-05, num_train_epochs=3; total time=  27.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:30, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.757900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.127100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.066300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=2e-05, num_train_epochs=4; total time=  35.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:30, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.336600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.618700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.274900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=2e-05, num_train_epochs=4; total time=  35.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.344900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.600100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.212800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.070200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.031600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=2e-05, num_train_epochs=4; total time=  35.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.198100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.421700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=3e-05, num_train_epochs=2; total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.276900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.499700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=3e-05, num_train_epochs=2; total time=  20.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.191200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.485300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=3e-05, num_train_epochs=2; total time=  20.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.268600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.552600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.238200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.085300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=3e-05, num_train_epochs=3; total time=  27.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.240200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.456000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.202400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.072800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=3e-05, num_train_epochs=3; total time=  27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.320100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.590100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.219200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.067900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=3e-05, num_train_epochs=3; total time=  27.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.540200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=3e-05, num_train_epochs=4; total time=  36.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:30, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.370500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.180500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=3e-05, num_train_epochs=4; total time=  35.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.207300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.348100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.120700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=3e-05, num_train_epochs=4; total time=  35.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.196500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=5e-05, num_train_epochs=2; total time=  20.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.079100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.256900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=5e-05, num_train_epochs=2; total time=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.255100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=5e-05, num_train_epochs=2; total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.180300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.009800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=5e-05, num_train_epochs=3; total time=  27.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.100900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.159300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.040900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=5e-05, num_train_epochs=3; total time=  27.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 00:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.127100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=5e-05, num_train_epochs=3; total time=  27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.266600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=5e-05, num_train_epochs=4; total time=  35.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.050200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=5e-05, num_train_epochs=4; total time=  35.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 00:30, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.174700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=2, learning_rate=5e-05, num_train_epochs=4; total time=  35.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.278800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=2e-05, num_train_epochs=2; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.304300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=2e-05, num_train_epochs=2; total time=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.306100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=2e-05, num_train_epochs=2; total time=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.270700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.741100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=2e-05, num_train_epochs=3; total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.339100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.742600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=2e-05, num_train_epochs=3; total time=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.234900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.636000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=2e-05, num_train_epochs=3; total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.272600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.637300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=2e-05, num_train_epochs=4; total time=  20.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:15, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.254500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.509300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=2e-05, num_train_epochs=4; total time=  19.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.415500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=2e-05, num_train_epochs=4; total time=  20.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.130800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=3e-05, num_train_epochs=2; total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.134500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=3e-05, num_train_epochs=2; total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.188000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=3e-05, num_train_epochs=2; total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.481700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=3e-05, num_train_epochs=3; total time=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.196900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.446100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=3e-05, num_train_epochs=3; total time=  16.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.322800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=3e-05, num_train_epochs=3; total time=  16.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.365800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=3e-05, num_train_epochs=4; total time=  20.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.262900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=3e-05, num_train_epochs=4; total time=  20.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.036600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.196300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=3e-05, num_train_epochs=4; total time=  20.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.922100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=5e-05, num_train_epochs=2; total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:08, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.919900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=5e-05, num_train_epochs=2; total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.955400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=5e-05, num_train_epochs=2; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.153900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=5e-05, num_train_epochs=3; total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.938700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.162500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=5e-05, num_train_epochs=3; total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.882800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.131500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=5e-05, num_train_epochs=3; total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.093900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=5e-05, num_train_epochs=4; total time=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.913000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.103200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=5e-05, num_train_epochs=4; total time=  20.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.842700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.079200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=4, learning_rate=5e-05, num_train_epochs=4; total time=  20.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=2e-05, num_train_epochs=2; total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=2e-05, num_train_epochs=2; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=2e-05, num_train_epochs=2; total time=   9.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.172700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=2e-05, num_train_epochs=3; total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.238200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=2e-05, num_train_epochs=3; total time=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.205200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=2e-05, num_train_epochs=3; total time=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.244300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=2e-05, num_train_epochs=4; total time=  15.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.171700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=2e-05, num_train_epochs=4; total time=  14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.155300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=2e-05, num_train_epochs=4; total time=  15.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=3e-05, num_train_epochs=2; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=3e-05, num_train_epochs=2; total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=3e-05, num_train_epochs=2; total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.050800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=3e-05, num_train_epochs=3; total time=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.115500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=3e-05, num_train_epochs=3; total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.067900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=3e-05, num_train_epochs=3; total time=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.105100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=3e-05, num_train_epochs=4; total time=  15.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.995500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=3e-05, num_train_epochs=4; total time=  15.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.986600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=3e-05, num_train_epochs=4; total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=5e-05, num_train_epochs=2; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=5e-05, num_train_epochs=2; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 00:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=5e-05, num_train_epochs=2; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.814400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=5e-05, num_train_epochs=3; total time=  12.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.914100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=5e-05, num_train_epochs=3; total time=  12.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.896700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=5e-05, num_train_epochs=3; total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.832300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=5e-05, num_train_epochs=4; total time=  15.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:13, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.724200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=5e-05, num_train_epochs=4; total time=  17.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.763300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=6, learning_rate=5e-05, num_train_epochs=4; total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='208' max='208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [208/208 00:24, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.032700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.201800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.043300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=BertClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;batch_size&#x27;: [2, 4, 6],\n",
       "                         &#x27;learning_rate&#x27;: [2e-05, 3e-05, 5e-05],\n",
       "                         &#x27;num_train_epochs&#x27;: [2, 3, 4]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3, estimator=BertClassifier(), n_jobs=1,\n",
       "             param_grid={&#x27;batch_size&#x27;: [2, 4, 6],\n",
       "                         &#x27;learning_rate&#x27;: [2e-05, 3e-05, 5e-05],\n",
       "                         &#x27;num_train_epochs&#x27;: [2, 3, 4]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: BertClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>BertClassifier(batch_size=4, learning_rate=3e-05, num_train_epochs=4)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BertClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>BertClassifier(batch_size=4, learning_rate=3e-05, num_train_epochs=4)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=BertClassifier(), n_jobs=1,\n",
       "             param_grid={'batch_size': [2, 4, 6],\n",
       "                         'learning_rate': [2e-05, 3e-05, 5e-05],\n",
       "                         'num_train_epochs': [2, 3, 4]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [2e-5, 3e-5, 5e-5],\n",
    "    \"batch_size\": [2, 4, 6],\n",
    "    \"num_train_epochs\": [2, 3, 4],\n",
    "}\n",
    "\n",
    "bert_clf = BertClassifier()\n",
    "grid = GridSearchCV(\n",
    "    estimator=bert_clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,            # 3‑fold CV\n",
    "    verbose=2,\n",
    "    n_jobs=1        \n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4893fe5-c896-459e-a161-72e461c3880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'batch_size': 4, 'learning_rate': 3e-05, 'num_train_epochs': 4}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found:\")\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33ecc632-4cf1-4260-9295-b817cccc8873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_num_train_epochs</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.793208</td>\n",
       "      <td>0.097771</td>\n",
       "      <td>1.629366</td>\n",
       "      <td>0.009816</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>4</td>\n",
       "      <td>{'batch_size': 4, 'learning_rate': 3e-05, 'num...</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.973534</td>\n",
       "      <td>0.013627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.625714</td>\n",
       "      <td>0.178327</td>\n",
       "      <td>1.699526</td>\n",
       "      <td>0.154765</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>3</td>\n",
       "      <td>{'batch_size': 4, 'learning_rate': 3e-05, 'num...</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>0.017969</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.102729</td>\n",
       "      <td>0.341063</td>\n",
       "      <td>1.358810</td>\n",
       "      <td>0.030899</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>4</td>\n",
       "      <td>{'batch_size': 6, 'learning_rate': 3e-05, 'num...</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>0.017969</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.262450</td>\n",
       "      <td>0.441576</td>\n",
       "      <td>2.377168</td>\n",
       "      <td>0.042898</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>4</td>\n",
       "      <td>{'batch_size': 2, 'learning_rate': 3e-05, 'num...</td>\n",
       "      <td>0.942446</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.326576</td>\n",
       "      <td>0.079230</td>\n",
       "      <td>2.354980</td>\n",
       "      <td>0.064214</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>3</td>\n",
       "      <td>{'batch_size': 2, 'learning_rate': 2e-05, 'num...</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.966340</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.393337</td>\n",
       "      <td>0.100905</td>\n",
       "      <td>1.579448</td>\n",
       "      <td>0.020752</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>3</td>\n",
       "      <td>{'batch_size': 4, 'learning_rate': 5e-05, 'num...</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.985612</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.966323</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.904393</td>\n",
       "      <td>0.070199</td>\n",
       "      <td>1.386865</td>\n",
       "      <td>0.052881</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>3</td>\n",
       "      <td>{'batch_size': 6, 'learning_rate': 5e-05, 'num...</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.966323</td>\n",
       "      <td>0.018936</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.502500</td>\n",
       "      <td>0.243641</td>\n",
       "      <td>1.609929</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>4</td>\n",
       "      <td>{'batch_size': 4, 'learning_rate': 2e-05, 'num...</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.992806</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.966305</td>\n",
       "      <td>0.018991</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.574683</td>\n",
       "      <td>0.063809</td>\n",
       "      <td>1.575228</td>\n",
       "      <td>0.008269</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>4</td>\n",
       "      <td>{'batch_size': 4, 'learning_rate': 5e-05, 'num...</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.963959</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.246142</td>\n",
       "      <td>0.212870</td>\n",
       "      <td>2.372437</td>\n",
       "      <td>0.070441</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>3</td>\n",
       "      <td>{'batch_size': 2, 'learning_rate': 3e-05, 'num...</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.963959</td>\n",
       "      <td>0.010125</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      18.793208      0.097771         1.629366        0.009816   \n",
       "1      14.625714      0.178327         1.699526        0.154765   \n",
       "2      14.102729      0.341063         1.358810        0.030899   \n",
       "3      33.262450      0.441576         2.377168        0.042898   \n",
       "4      25.326576      0.079230         2.354980        0.064214   \n",
       "5      14.393337      0.100905         1.579448        0.020752   \n",
       "6      10.904393      0.070199         1.386865        0.052881   \n",
       "7      18.502500      0.243641         1.609929        0.016371   \n",
       "8      18.574683      0.063809         1.575228        0.008269   \n",
       "9      25.246142      0.212870         2.372437        0.070441   \n",
       "\n",
       "   param_batch_size  param_learning_rate  param_num_train_epochs  \\\n",
       "0                 4              0.00003                       4   \n",
       "1                 4              0.00003                       3   \n",
       "2                 6              0.00003                       4   \n",
       "3                 2              0.00003                       4   \n",
       "4                 2              0.00002                       3   \n",
       "5                 4              0.00005                       3   \n",
       "6                 6              0.00005                       3   \n",
       "7                 4              0.00002                       4   \n",
       "8                 4              0.00005                       4   \n",
       "9                 2              0.00003                       3   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'batch_size': 4, 'learning_rate': 3e-05, 'num...           0.964029   \n",
       "1  {'batch_size': 4, 'learning_rate': 3e-05, 'num...           0.949640   \n",
       "2  {'batch_size': 6, 'learning_rate': 3e-05, 'num...           0.949640   \n",
       "3  {'batch_size': 2, 'learning_rate': 3e-05, 'num...           0.942446   \n",
       "4  {'batch_size': 2, 'learning_rate': 2e-05, 'num...           0.956835   \n",
       "5  {'batch_size': 4, 'learning_rate': 5e-05, 'num...           0.956835   \n",
       "6  {'batch_size': 6, 'learning_rate': 5e-05, 'num...           0.949640   \n",
       "7  {'batch_size': 4, 'learning_rate': 2e-05, 'num...           0.956835   \n",
       "8  {'batch_size': 4, 'learning_rate': 5e-05, 'num...           0.956835   \n",
       "9  {'batch_size': 2, 'learning_rate': 3e-05, 'num...           0.949640   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.992806           0.963768         0.973534        0.013627   \n",
       "1           0.992806           0.963768         0.968738        0.017969   \n",
       "2           0.992806           0.963768         0.968738        0.017969   \n",
       "3           0.978417           0.978261         0.966375        0.016920   \n",
       "4           0.978417           0.963768         0.966340        0.008997   \n",
       "5           0.985612           0.956522         0.966323        0.013640   \n",
       "6           0.992806           0.956522         0.966323        0.018936   \n",
       "7           0.992806           0.949275         0.966305        0.018991   \n",
       "8           0.964029           0.971014         0.963959        0.005789   \n",
       "9           0.971223           0.971014         0.963959        0.010125   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                2  \n",
       "2                2  \n",
       "3                4  \n",
       "4                5  \n",
       "5                6  \n",
       "6                6  \n",
       "7                8  \n",
       "8                9  \n",
       "9                9  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERTscores_df = pd.DataFrame(grid.cv_results_)\n",
    "BERTscores_df = BERTscores_df.sort_values(by=['rank_test_score']).reset_index(drop='index')\n",
    "BERTscores_df.head(10)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4049c251-09cf-491a-b002-03bf1bac7eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df[\"label\"] = test_df[\"Class\"].map(label_to_id)\n",
    "X_test = test_df[\"Text\"].tolist()\n",
    "y_test = test_df[\"label\"].tolist()\n",
    "y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cae30c97-1cb3-495c-8021-1e41b129ddf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT: 0.9856115107913669\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       0.96      1.00      0.98        26\n",
      "           2       1.00      1.00      1.00        24\n",
      "           3       1.00      0.96      0.98        26\n",
      "           4       0.97      0.97      0.97        30\n",
      "\n",
      "    accuracy                           0.99       139\n",
      "   macro avg       0.99      0.99      0.99       139\n",
      "weighted avg       0.99      0.99      0.99       139\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"BERT:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=id_to_label.values())\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d2021-4585-4e0f-b6a2-ea5d317f8562",
   "metadata": {},
   "source": [
    "#### Main Findings:\n",
    "\n",
    "1. 99% accuracy on the predictions using BERT with batch_size = 4, learning_rate =3e-05, num_train_epochs = 4\n",
    "\n",
    "2. learning_rate: The model does best on a medium learning rate (3e-05) than low (2e-05) or a higher one (5e-05)\n",
    "\n",
    "3. Increasing epochs to 4 helped the model learn better document embeddings.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc504a1-35c7-46e5-93de-5d3da5671efe",
   "metadata": {},
   "source": [
    "### Task 4: Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a968b-90f5-4eef-a0b9-f63a8ea2ca4d",
   "metadata": {},
   "source": [
    "#### Main conclusions from the evaluations in Tasks 1, 2 and 3:\n",
    "\n",
    "|Task|Conclusions|\n",
    "|-----|----------|\n",
    "|**CountVec**| ~94% accuracy using CountVectorizer + Logistic Regression; adding bigrams further improves performance; extremely fast and easy to interpret. |\n",
    "|**Doc2Vec**| ~97% accuracy with Doc2Vec (PV-DBOW, 128-dim embeddings, 60 epochs); captures the context in which the word is present, at the cost of longer training time. |\n",
    "|**BERT**| ~99% accuracy by fine-tuning BERT to best parameters: learning rate 3 ×10⁻⁵, batch size 4, 4 epochs; offers best accuracy given its capability to predict masked tokens in a sentence and to predict sentence sequences but requires high compute resources. |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5697fc3-358b-430d-8679-d5ba45ee8c11",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#### Steps taken to ensure that the models are operating correctly:\n",
    "\n",
    "1. All experiments used stratified and standardised train/test splits to prevent class imbalance.\n",
    " \n",
    "2. Using pipelines to ensure that preprocessing, vectorization/tokenization, and classification always ran in the correct order to prevent data leakage. \n",
    "\n",
    "3. Hyperparameters were tuned via exhaustive grid searches. Although I had to ration my CV process based on how computationally heavy it got, I am fairly happy with the accuracies I achieved. Even when we manually conduct an error analysis, it’s easy to point out that the model is getting confused between business and politics or tech and business, which is a predictable error, versus a broken code or leakage problem.\n",
    "\n",
    "4. Fixed random seeds (random_state=42, seed=42) across all frameworks (scikit-learn, Gensim, Hugging Face) to ensure that each model’s performance was repeatable.\n",
    "\n",
    "5. Downloaded all the required libraries to conduct these experiments progressively as I encountered errors.\n",
    "\n",
    "\n",
    "The non-winning models differed by only a few tenths of a percent and had very low standard deviations across folds. This means that they too were trained correctly and their lower rankings were due to genuine, but small, performance gaps—not implementation bugs.\n",
    "\n",
    "If I had access to a machine that could compute faster, I would do the following tests to comprehend the dynamics of hyper-parameters better:\n",
    "\n",
    "1. Limit the vocabulary size using the vector-size hyperparameter in Doc2Vec and try to find the model that would give me a similar accuracy to the rank 1 model.\n",
    "\n",
    "2. Dig deeper into the role of dm in Doc2Vec, examining in which classification tasks PBOW performs better than PDM.\n",
    "\n",
    "3. Use other model names for BERT, also reducing max_length and running tests to capture the difference.\n",
    "\n",
    "4. Running the models with different test sizes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd3ce3-703e-4601-be7a-bdd3e505acdf",
   "metadata": {},
   "source": [
    "My overall understanding of this task is that all the ways of vectorizing the numeric data seem to be efficient depending on the task they are going to be employed for and the access to compute resources. If we want to have a fast and simple NLP solution without getting into the semantics of the language and staying at the syntactic level, CountVectorizer with 94% accuracy is not at all bad. However, if we are looking at tasks that need some understanding of the meanings of phrases, which helps us with our sparsity problem and the database is medium-sized, I believe Doc2Vec should be the choice. BERT could be used when deep contextual understanding and capturing long range semantic dependency is absolutely essential. It is by far the most accurate, can take in huge databases but comes at a huge cost of computational resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
